[{"categories":null,"content":"前言  前两天手机在使用过程中，无故死机，重启发现在logo显示画面停留一会儿又重启，后面就一直不断的循环这个过程。 本来以为重新做系统就好了，没想到再还原回去还是一样。我以为就这么变砖了，最后还是因为穷的力量，搜索nexus6p无限重启原因就发现原来这是由于前几天我手机摔过一次，可能导致cpu虚焊部分出了毛病，才导致现在手机无限重启的情况。 没办法，通过这几天各种google，终于找到网络上很多大神都有解决的方案，后面后提供大神帖子链接。\n 准备工作  备份当前的文件和数据 在手机上启用USB调试和OEM解锁 下载ADB驱动程序，安装到你的PC机里。这里有个问题，要安装低版本的，大于29.0的版本再使用时报了个错误,提示找不到可用的命令，网上解决方法就是下载安装26.0版本的解决了这个问题。 去这里下载符合nexus6p的TWRP，这里我下载了3.3.1版本的 去magisk官网下载最新版本应用包括manage 下载要用到的刷机固件Lineage OS，原厂镜像 Nexus6p 下载我打包的要用到的boot.img  备份  由于已经进入不了系统了，备份需要链接USB进到REF里使用这个方法adb pull sdcard备份自己重要的数据\n 开始刷系统  这里要提一点，一开始我找到的方法是刷指定原厂镜像，刷写4核boot.img就可以重新进入系统。后面又找到不一定原厂镜像的版本，比如lingage17.1的镜像也可以通过大神的方法。 所以，这两种方法都可以解决无限重启进不了系统的问题，我都写在这里，只要看一种方法就好了。\n 第一种方法：刷原厂镜像  先说一下刷原厂镜像7.1.2版本号n2g48c,参考文档,英文原档\n  具体怎么刷参考文档里已经写得很清楚了，主要说一下，如果没有刷过twrp的先刷这个fastboot flash recovery twrp3_1_1_4Cores.img 先线刷7.1.2, 具体线刷的操作，即进入TWRP界面，选Advanced再点sideload，滑块确认，等待pc端执行adb sideload angler-ota-n2g48c-b004b71e.zip 接下来刷入修改版本的boot:adb flash boot 6p48C.img 如果前面你先刷twrp就不用再刷一次了。 最后就是进入twrp卡刷性能包6pEX4_1_2.zip。具体操作：把zip包上传到手机sdcard,在twrp界面选择install指定的zip包安装，一路下一步就可以了。如果需要优化就得自己研究其他选项了。 以上就可以完美开机了。  第二种方法：刷第三方镜像lineage 17.1  理论上刷其他所有的镜像都可以使用这个方法重进系统。参考文档\n  下载重要的改写cpu核心的软件N5x-6P_BLOD_Workaround_Injector_Addon-AK3-signed USB链接手机，使用命令adb reboot bootloader重启 进入原先系统已经刷过twrp的可以直接进入twrp线刷lineage 17.1adb sideload lineage-17.1-20200308-UNOFFICIAL-angler.zip 参考文档 刷写twrp fastboot flash recovery twrp-3.3.1-0-fbe-4core-angler.img 然后进入REC模式，上传zip包到sdcard,线刷Addon-AK3.signed.zip这个包adb sideload N5X-6P_BLOD_Workaround_Injector_Addon-AK3-signed.zip 最后重启，等待一会儿就可以进入系统了。  解决指纹功能bug问题  就上一篇文章，我再刷PixelExperience时已经提到过，使用magisk安装补丁的方法重新刷boot就好了。参考文档\n  上传boot-17.img到手机adb push boot-17.img sdcard/ 在手机里安装最新版本的magisk manager 打开magisk点击安装-\u003e安装-\u003e选择要安装的boot-17.img magisk manager 将生成新的文件magisk_patched.img到sdcard/Download/ 下载这个补丁到PC机adb pull /sdcard/Download/magisk_patche.img 最后重启进入bootloader刷写这个补丁fastboot flash boot magisk_patched.img 以上完成就可以重进系统使用指纹的功能了。  总结  其实这两个方法最主要是线刷的zip包不同，第二种方法里的AK3包实现了任何系统修改cpu4核心的方法。\n 下载  我打包了一下所有要用到的软件（不包括原厂镜像包，这些都可以去官网下载)，防止原链接失效。备份包\n ","description":"","tags":["bootloop","nexus6p","android","magisk"],"title":"Nexus6p虚焊导致无限重启之救砖教程","uri":"/posts/bootlooping-nexus6p-fix/"},{"categories":null,"content":" Android 10.0也出来一段时间了，想着给自己的手机刷一下。所以就有了这个攻略，记录一下过程。\n 准备工作  确保设备电池电量超过50% 备份当前的文件和数据 在手机上启用USB调试和OEM解锁 下载ADB驱动程序，安装到你的PC机里 去这里下载符合nexus6p的TWRP，这里我下载了3.3.1版本的 去magisk官网下载最新版本应用包括manage 下载刷机的固件PixelExperience 10  使用ADB和Fastboot解锁Bootloader 打开终端运行如下命令重启手机到fastboot模式，参考\nadb reboot bootloader fastboot flashing unlock 完成以后，就成功解锁了Bootloader，再次检查以启用“开发人员选项”，然后转到“开发人员选项”并启用USB调试模式OEM解锁。有时，他们在启动后会自行禁用。\n安装TWRP 还是一样先进到启动模式，把TWRP镜像刷进recovery,如下\nadb reboot bootloader fastboot flash recovery twrp-3.3.1-0-angler.img  完成上面两个准备刷机的步骤基本上就不用担心手机变砖了，下面开始刷机\n 刷PixelExperience 10 到Nexus6p 首先确保Nexus6p没有刷过其他第三方Rom，如果刷过，要先通过官方Rom还原到指定版本 这里我们需要下载8.1.0 (OPM7.181205.001, Dec 2018)版本，解压进入文件夹执行shell就可以还原了。当然首先还得USB链接成功。\n刷入Pixel 10固件 确保nexus6p是最新版本8.1.0以后，我们就可以通过TWRP刷入Pixel这个最新的固件了\n重启手机，进入手机端的TWRP界面，点选Advanced选项，然后在手机界面里点选ADB sideload选项，然后滑动下面的滑块确认选择，等待电脑端执行adb sideload 刷机包名.zip命令\n这里有一点要注意，下载固件的时候要把版本10的两个文件都下载了，因为最新的那版本指纹，锁屏功能有问题。\nunzip -x PixelExperience_angler-10.0-20191231-1607-OFFICIAL.zip -d piexl2019 unzip -x PixelExperience_angler-10.0-20200101-0925-OFFICIAL.zip -d piexl2020 cp piexl2019/boot.img piexl2020 cd piexl2020 zip -r -v -o pixel20200101.zip . 完成以上，生成我们要刷入的pixel20200101.zip这个固件包了，可以进入TWRP界面三清数据以后线刷就OK了 这里的三清指的是擦除system \u0026 data \u0026 cache 这三个分区，还有格式化data分区 最后执行以下，重启就能进入新系统了\nadb sideload pixel20200101.zip 到这里，如果不需要Root手机的话就不用看下面的了\nRoot提权 参考 首先进到新系统（别忘了还是要先开启开发者选项）安装magisk manager这个app,把上一步解压出来的boot.img复制到手机里\nadb push boot.img /sdcard/ 操作magisk manager安装magisk的补丁，生成magisk_patched.img 把补丁下载回PC\nadb pull /sdcard/Download/magisk_patched.img . 重启手机进入快速启动模式,把补丁刷入boot\nfastboot flash boot magisk_patched.img 最后重启手机，进入magisk manager检查root权限。\n参考  PixelExperience for Google Nexus 6P 【angler】 【ROM】【UNOFFICIAL】LineageOS 17.1 for Nexus 6P (angler) 【教程】一加5刷LineageOS全过程  ","description":"","tags":["android","nexus6p","twrp","magisk"],"title":"Nexus6p Root提权以及刷机攻略","uri":"/posts/root-nexus6p-use-twrp-magisk/"},{"categories":null,"content":"准备  Raspberry Pi 2 Model B Rev 1.1 SD卡闪盘(4G+) 主机我用的是ArchLinux,内核4.19.52-1-lts 主路由器一个TPlink USB网卡 一条网线  刷openwrt固件 下载解压 去官网下载对应的安装固件\nwget http://downloads.openwrt.org/releases/18.06.4/targets/brcm2708/bcm2709/openwrt-18.06.4-brcm2708-bcm2709-rpi-2-ext4-factory.img.gz gzip -d openwrt-18.06.4-brcm2708-bcm2709-rpi-2-ext4-factory.img.gz 烧写SD卡 sudo fdisk -l #列出闪盘设备名 /dev/mmcblk0 sudo dd if=openwrt-18.06.4-brcm2708-bcm2709-rpi-2-ext4-factory.img of=/dev/mmcblk0 链接树莓派 配置主机IP(192.168.1.1) 网线直接连接树莓派接口 浏览器打开192.168.1.1 配置密码和ssh登陆以后，在终端里登陆ssh root@192.168.1.1\n修改lan口配置如下：\ncat /etc/config/network config interface 'lan' option type 'bridge' option ifname 'eth0' option proto 'static' option netmask '255.255.255.0' option ip6assign '60' option ipaddr '192.168.10.109' option gateway '192.168.10.1' option broadcast '255.255.255.0' option dns '114.114.114.114' 重启路由，用网线连接主路由器就可以链接外网了。\n安装软件 安装支持网卡的模块\nopkg update opkg install kmod-rtl8192cu 修改无线网络配置 cat /etc/config/wireless config wifi-iface 'default_radio0' option device 'radio0' option network 'lan' option mode 'ap' option encryption 'none' option ssid 'CMCCFREE' 修改路由网络配置  cat /etc/config/network config interface 'loopback' option ifname 'lo' option proto 'static' option ipaddr '127.0.0.1' option netmask '255.0.0.0' config globals 'globals' option ula_prefix 'fd3c:ca1e:c593::/48' config interface 'lan' option proto 'static' option netmask '255.255.255.0' option ipaddr '192.168.10.1' option ip6assign '64' config interface 'wan' option ifname 'eth0' option proto 'dhcp' option dns '127.0.0.1' #### 连接该 OpenWrt 路由器的所有设备发出的 DNS 请求都会由该路由器的 dnsmasq 来响应（当然，前提是设备没有手动去修改默认的 DNS 服务器 IP，而使用路由器默认提供的 DNS 服务器 IP）。 option peerdns '0' #### 忽略通告的DNS服务器地址 修改DHCP配置如下 root@OpenWrt:~# cat /etc/config/dhcp config dnsmasq option domainneeded '1' option localise_queries '1' option rebind_protection '1' option rebind_localhost '1' option domain 'lan' option expandhosts '1' option authoritative '1' option readethers '1' option leasefile '/tmp/dhcp.leases' option nonwildcard '1' option localservice '1' option logqueries '1' option noresolv '1' option local '/lan/' option allservers '1' list server '114.114.114.114' #### 配置DNS转发 注意，此为路由器默认查询的 DNS 服务器，你可以根据你的实际情况选择一个较快的 DNS 服务器 config dhcp 'lan' option interface 'lan' option dhcpv6 'server' option ra 'server' option ra_management '1' config dhcp 'wan' option interface 'wan' option ignore '1' 提交修改并重启 uci commit /etc/config/wireless uci commit /etc/config/network uci commit /etc/config/dhcp ## 重启路由也是一样的或者执行以下命令重启服务 /etc/init.d/dnsmasq restart /etc/ini.d/network restart ifup wan \u0026\u0026 wifi 安装SS 安装 shadowsocks-libev 相关的包 opkg update opkg install shadowsocks-libev-config shadowsocks-libev-ss-local shadowsocks-libev-ss-redir shadowsocks-libev-ss-rules shadowsocks-libev-ss-tunnel luci-app-shadowsocks-libev 基础配置 进入openwrt web配置界面，选择 Service-\u003eshadowsocks-libev\n点击 Remote Servers, 里面已经默认配置一个服务器 sss0，修改地址，端口，密码，加密方式，最重要的，将disabled的勾去掉，点击 save\u0026apply 按钮。\n再点击 Local Instances, 点击 ss-local.cfgXXXXX (XXX为随机数字)条目对应的Disabled 按钮，将其变成 Enabled，点击 Save \u0026 Apply。配置保存生效以后, ss-local.cfgXXXX 条目的Running 状态由no变为yes。这时，路由器上已经运行一个SOCKS5服务器，端口1080。设置电脑浏览器的代理服务器为路由器地址，端口1080，尝试访问谷歌，如果成功则说明ss客户端在openwrt上工作一切正常。\n接着要测试iptables+ss-redir自动转发代理(透明代理)的功能，在Local Instances中，将ss-redir.hi 设为Enabled。再点击 Redir Rules, Disabled勾去掉，点击Destination Settings，dst default 由bypass改为 forward。点击Save\u0026Apply 使配置生效。将电脑浏览器的代理设置取消，访问谷歌，如果成功，则说明无条件透明代理设置成功。所有数据包都由路由器转发到ss服务器了。\n3. 进阶配置 上面最后配置的透明代理将全部流量都转发到远端SS服务器，显然太浪费流量，而且国内的网站去国外转一圈效率也很低。因此我们需要在路由器上识别国内国外流量，区别对待。\n1.首先将 Destination Settings中的dst forward 设为 bypass。\n将opkg列表更新由http 改为https, http存在更新不全的情况，可能是GFW搞鬼  opkg install libustream-mbedtls (如果提示找不到，opkg update 多运行几次) sed -i s/http:/https:/g /etc/opkg/distfeeds.conf opkg update 安装各种依赖包  opkg remove dnsmasq opkg install dnsmasq-full opkg install coreutils-base64 curl ca-certificates ca-bundle 问题总结 dnsmasq服务不启动 最早手动添加域名到 /etc/dnsmasq.d/下的配置文件中，经过测试，发现无法解析该域名，经过排查，可能是配置文件编码格式的问题，导致了dnsmasq服务无法启动\n主机路由地址 排查问题我们在主机上用nslookup\ngraz@graz ~ % nslookup twitter.com Server:\t192.168.1.1 Address:\t192.168.1.1#53 Non-authoritative answer: Name:\ttwitter.com Address: 104.244.42.65 Name:\ttwitter.com Address: 104.244.42.1 如上，看server项，是上上级的路由地址，这就绕过了树莓派的路由直接走上级路由查询。\n然后，我们再看一下cat /etc/resolv.conf 可以看到有多个路由地址，包括192.168.10.1，192.168.1.1\n以上，主机路由地址获取到了上上级的路由，也不知道怎么回事，(有知道的可以邮件通知我一下，谢谢大家)，只能先手动修改一下主机路由如下:\ncat /etc/resolv.conf nameserver 192.168.10.1 ## 这里是树莓派路由器的路由地址，一开始获取的还有上上级的路由地址如：192.168.1.1 。要把这个删掉 最后 最后，查看日志或者安装tcpdump抓取5353端口看是否正常配置\nopkg update opkg install tcpdump tcpdump -vv -i lo port 5353 参考  OpenWRT Shadowsocks+GFWList 流量自动分流 openwrt 18.06.1 配置科学上网 Shadowsocks + OpenWRT + dnsmasq-full + ipset + gfwList 实现路由器 新的基于OpenWrt路由器的（不完全）自动翻墙方案  ","description":"","tags":["openwrt","raspberry"],"title":"树莓派安装配置软路由","uri":"/posts/openwrt-raspberry/"},{"categories":null,"content":"前言 openwrt是一款基于linux的路由器系统，可以安装很多相关的工具包，完成像linux系统服务器可以完成的工作，比如今天我们要讲的路由器的网络数据包抓包。\n环境  安装了openwrt的路由器，ip地址：192.168.10.1 要抓包流量的Android手机，ip地址：192.68.10.235 工作台笔记本，ip地址：192.168.10.234  安装与配置  以下介绍两种方法都可以实现路由器数据包抓取的功能\n 简单的说明 根据openwrt文档，所有的局域网的数据最后都是通过br-lan虚拟网卡来做转发，所以对此网卡进行监控即可 此命令本质是远程在路由器上执行网络监控命令，输入文本到本机的wireshark里面 使用wireshark作为可视化工具来查看\n捕获与tcpdump的通信  Tcpdump可以安装在OpenWrt路由器上。因此，这种方法消除了让远程Wireshark或类似听众实时分析流量的需要。\n ssh登陆到openwrt(默认端口：22)，更新并安装tcpdump\nopkg update opkg install tcpdump 执行以下命令在接口（-i）上侦听并将捕获的信息存储到文件（-w），并在执行此操作时（-v）进行冗长操作。\ntcpdump -i any -v -w pcap.cap 生成的pcap.cap文件，我们可以传回工作台，用wireshark打开做进一步的分析\n 以下是一些使用tcpdump的例子：\n  https://www.rationallyparanoid.com/articles/tcpdump.html  制作一键命令脚本 命令格式如下：\nssh -p ssh端口 -o StrictHostKeyChecking=no ssh用户名@ssh地址 'tcpdump -s 0 -U -n -w - -i br-lan not port ssh端口' | wireshark -k -i - 由于我环境配置了不用密码登陆的方式所以我们可以直接写成如下：\nssh openwrt 'tcpdump -s 0 -U -n -w - -i br-lan not port 22' | wireshark -k -i - ssh -p 22 -o StrictHostKeyChecking=no root@192.168.10.1 'tcpdump -s 0 -U -n -w - -i br-lan not port 22' | wireshark -k -i -  前面讲述了基本的原理和操作手段，但是缺点是每次都需要输入长串命令行和密码，可以利用linux的一些小操作技巧，简化此过程，做成一个命令工具，方便随时调用。 基本原理：\n  使用 sshpass 工具来做密码输入 使用 alias 别名来做成命令语句  在工作台安装sshpass，执行以下脚本：\nsudo pacman -S sshpass sshpass -p 'password' ssh -p 22 -o StrictHostKeyChecking=no root@192.168.10.1 'tcpdump -s 0 -U -n -w - -i br-lan not port 22' | wireshark-gtk -k -i - 把执行语句写到.bash_rc就可以一条命令执行抓包分析了\nalias tsharkbyopenwrt=\"sshpass -p 'password' ssh -p 22 -o StrictHostKeyChecking=no root@192.168.10.1 'tcpdump -s 0 -U -n -w - -i br-lan not port 22' | wireshark-gtk -k -i -\" 完善脚本 通过命名管道来导回数据\nmkfifo /tmp/fifo sshpass -p 'passwrod' ssh openwrt 'tcpdump -s 0 -U -n -w - -i br-lan not port 22' \u003e /tmp/fifo \u0026 wireshark-gtk -k -i /tmp/fifo 这里我配置了.ssh/config，所以可以直接使用ssh openwrt命令代替前面指定端口与用户名的方式。\n 我们还有一个方法可以不用安装sshpass,直接使用密钥的方式来登陆路由器抓包,以上就可以写为：\n ssh-copy-id openwrt ssh openwrt 'tcpdump -s 0 -U -n -w - -i br-lan not port 22' \u003e /tmp/fifo \u0026 wireshark-gtk -k -i /tmp/fifo 使用远程Wireshark侦听器进行分析 ssh登陆到openwrt(默认端口：22)，更新并安装iptables-mod-tee\nopkg update opkg install iptables-mod-tee 运行以下iptables命令以“在输出接口（-o）上将源IP（-s）的每个数据包的副本转发到网关IP（ - 网关）”\niptables -A POSTROUTING -t mangle -o br-lan ! -s 192.168.10.235 -j TEE --gateway 192.168.10.234 运行以下iptables命令以“在接口（-i）上将目的IP（-d）的每个数据包的副本转发到网关IP（ - 网关）”\niptables -A PREROUTING -t mangle -i br-lan ! -d 192.168.10.235 -j TEE --gateway 192.168.10.234 在Wireshark上开始捕获流量并应用下面的过滤器：\n(ip.src == 192.168.9.121) || (ip.dst == 192.168.9.121) 关于iptable规则一些有用的资源：\n https://wiki.openwrt.org/doc/howto/netfilter http://www.faqs.org/docs/iptables/index.html http://ipset.netfilter.org/iptables-extensions.man.html#lbDW  安装使用CloudShark CloudShark是一个独立的，与LEDE无关的云分析平台。它依靠cshark插件远程发送数据包进行分析。请检查您的内部规则，是否允许将网络流量发送到云平台。\nopkg update opkg install cshark luci-app-cshark 请查看Cloud Shark文档以获取更多信息。\n问题处理 在工作台使用wireshark-gtk的时候报错：\nCouldn't run /usr/bin/dumpcap in child process: Permission denied 这是由于dumpcap这个的权限问题。\nll /usr/bin/dumpcap :( -rwxr-xr-- 1 root wireshark 102K May 23 06:39 /usr/bin/dumpcap 只要把当前用户加入到wireshark用户组里，重启就ok了（暂时不明为什么一定要重启，反正我是重启以后才正常使用的)。\nsudo usermod -aG wireshark $LOGNAME sudo setcap cap_net_raw,cap_net_admin+eip /usr/bin/dumpcap setcat对应使用getcap查看当前的方法权限\n参考  ANALYZING NETWORK TRAFFIC WITH OPENWRT How to capture, filter and inspect packets GETTING STARTED WITH OPENWRT – LINUXFYING ROUTERS  ","description":"","tags":["openwrt","wireshark","cloudshark"],"title":"用OPENWRT路由器抓包网络流量笔记","uri":"/posts/openwrt-wireshark-setting/"},{"categories":null,"content":"前言  最近新入手一台Thinkpad,使用UEFI+GPT预安装好了Win10操作系统，准备开始安装Archlinux。\n 如果你准备在一块新硬盘上安装双系统，那么应该先安装windows。 如果你安装的是Win10，那么它应该默认就是按UEFI+GPT方式安装的，可以按Win+X键打开磁盘管理，如果是UEFI安装的，那么应该有一个EFI分区，可能是250M。 其它还有Windows的恢复分区和基本数据分区。不用管恢复分区，如果现在磁盘上没有剩余空间，可以右键点击基本数据分区，点击压缩卷，给Arch的安装腾出空间。用右键点击磁盘，查看属性，可以知道自己是否采用了GPT分区方式。\n在安装之前，请在电源计划中关掉Windows的快速启动，并在BIOS中关掉Secure Boot，可以很容易搜到对应自己电脑的具体方法。 如果上面有哪一条没有满足，请只看一看我遇到的问题，具体安装请再参考其它教程\n安装 安装之前  准备一个大于4G的U盘 安装镜像，可以从Arch Linux的官方网站下载  制作U盘启动盘 这里我只介绍linux系统下使用dd的方式，windows下面的方法可以看一下这个安装教程\n插入U盘，查看U盘设备名,不需求挂载\nlsblk sudo dd if=archlinux-2018.06.01-x86_64.iso of=/dev/sdb 这样，就制作好了U盘启动了，把U盘插入要安装的机子，配置BIOS通过U盘启动，就可以进入光盘引导的临时系统。\n选择镜像源 Arch Linux是通过网络进行安装的，为了以更快的速度下载软件包，建议先配置镜像源。配置镜像源的方法是编辑/etc/pacman.d/mirrorlist这个文件，将想用的镜像源的放到第一个非井号开头的行即可。如下可将中科大镜像源作为首选镜像源。\n# /etc/pacman.d/mirrorlist # This is the USTC mirror Server = http://mirrors.ustc.edu.cn/archlinux/$repo/os/$arch # and other mirrors ## Score: 4.6, China Server = http://mirrors.163.com/archlinux/$repo/os/$arch # 配置完成后可以执行pacman -Syy试一下，可以看一下pacman从镜像站下载文件的速度。\n分区  我们前面提过已经默认有安装的Win10系统,使用fdisk可以看到已经有一个EFI分区为250M大小。因此不要单独为Linux分出EFI分区，因为要双系统启动的话应该把Win10的EFI分区挂载到/boot上。\n 以下是我的硬盘分区情况,因为我还有一块硬盘用来挂载/home，所以我只要创建根分区和swap分区\nDevice Start End Sectors Size Type /dev/nvme0n1p1 2048 534527 532480 260M EFI System /dev/nvme0n1p2 534528 567295 32768 16M Microsoft reserved /dev/nvme0n1p3 567296 254337023 253769728 121G Microsoft basic data /dev/nvme0n1p4 254337024 485023743 230686720 110G Linux filesystem /dev/nvme0n1p5 498069504 500117503 2048000 1000M Windows recovery environment /dev/nvme0n1p6 485023744 497606655 12582912 6G Linux swap 格式化 mkfs.ext4 /dev/nvme0n1p4 mkswap /dev/nvme0n1p6 swapon /dev/nvme0n1p6 挂载分区 首先，一定是先挂载/分区，再挂载其它分区。因为要使用双系统启动，所以即使没有分/boot分区，还是应该把windows的EFI分区挂载到/上。\nmount /dev/nvme0n1p4 /mnt/ mkdir -p /mnt/boot mount /dev/nvme0n1p1 /mnt/boot 基本软件安装 安装Arch Linux的软件很简单，执行下面这条命令就行了：\npacstrap /mnt base base-devel 配置系统 创建fstab 生成一个fstab文件（使用-U或-L分别由UUID或标签定义）：\ngenfstab -U /mnt \u003e\u003e /mnt/etc/fstab 切换新系统 现在我们执行arch-chroot /mnt，这样就以chroot的方式进入了新的系统。\n配置时间 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime hwclock --systohc 配置本地化 在/etc/locale.gen中取消注释en_US.UTF-8 UTF-8和其他所需的本地化，并使用local-gen更新本地语言编码\n设置主机名 echo 'hcaijin.com' \u003e /etc/hostname 设置root密码 passwd 设置启动 按照上面的步骤，efi分区应该被挂载到了/boot目录下。这时，我们使用bootctl install命令，安装bootloader，然后用cp /usr/share/systemd/bootctl/arch.conf /boot/loader/entries/把示例文件复制过来，只要修改它的options部分就可以了。 以我的/boot分区为例，用blkid -s PARTUUID -o value /dev/nvme0n1p1就可以生成所需要的PARTUUID，最后加上rw就行了。\n格式大概为：\ntitle Arch Linux linux /vmlinuz-linux initrd /initramfs-linux.img options root=UUID=6278bd34-44cd-41b9-9bdd-239d9ce4020a rw 意思是创建一个标题为Arch Linux的启动项，它用bootloader所在分区(/dev/sda1)根目录下的vmlinuz-linux作为Linux内核，initramfs-linux.img作为initramfs镜像(可以认为是一个临时rootfs镜像)，并且用root=/dev/sda2 ro作为内核参数。\n再编辑/boot/loader/loader.conf.\ntimeout 3 default arch 意思是默认用arch.conf的配置启动，等待3秒没有键盘操作即使用默认配置启动。\n新系统的网络 启动盘中默认配置好了有关网络的软件，但新的系统中却没有。 如果你只是使用单一且固定的有线网络，使用systemctl enable dhcpcd@interface.service就可以了（interface是你的网络接口名，可以使用ip link查看，类似enp3s0）。 如果要使用无线网络，那么就要使用pacman -S iw wpa_supplicant dialog命令安装这些软件包。如果失败，可能要安装固件。\n至此，新系统的配置就完成了。\n使用exit命令退出chroot环境，umount -R /mnt卸载挂载的分区，然后使用reboot重启一下就好了。\n最后 可能会启动失败，解决方法是进入BIOS里的设置把UEFI作为唯一的启动方式。然后保存退出，就可以看到有三个启动项（分别是Arch Linux, Windows Manage, Default），选择你要进入的系统就可以了。\n","description":"","tags":["archlinux","windows","uefi"],"title":"UEFI+GPT安装Archlinux与Win10双系统教程","uri":"/posts/archlinux-uefi-bootloader/"},{"categories":null,"content":" 根据官方文档 https://www.chromium.org/chromium-os/quick-start-guide 只有Ubuntu Trusty版本的安装方式写了个ArchLinux的安装方法\n 安装依赖  Arch Linux 4.16.12-1-ARCH x86_64 GNU/Linux 有sudo权限的用户  基本依赖 确保有如下包就好了，没有就用pacman -S 安装就是：\nsudo pacman -S git-core gitk git-gui subversion curl lvm2 thin-provisioning-tools python-pkg-resources python-virtualenv python-oauth2client 安装depot_tools 用git克隆下来就好了,但要注意python的版本，后面会说.\ncd ~/Source/ git clone https://chromium.googlesource.com/chromium/tools/depot_tools 确保deport_tools目录在PATH变量里\nsudoers配置 要设置Chrome操作系统构建环境，应该关闭sudo的tty_tickets选项，因为它与cros_sdk不兼容。执行如下操作：\ncd /tmp cat \u003e ./sudo_editor \u003c\u003cEOF #!/bin/sh echo Defaults \\!tty_tickets \u003e \\$1 # Entering your password in one shell affects all shells echo Defaults timestamp_timeout=180 \u003e\u003e \\$1 # Time between re-requesting your password, in minutes EOF chmod +x ./sudo_editor sudo EDITOR=./sudo_editor visudo -f /etc/sudoers.d/relax_requirements 获取源码 创建一个目录来保存源文件“${SOURCE_REPO}”。\nexport SOURCE_REPO=\"~/Source/chromiumos\" mkdir ${SOURCE_REPO} cd ${SOURCE_REPO} virtualenv -p /usr/bin/python2 venv\t#这里我们要把python环境切换为2.7，才能使用下面的repo repo init -u https://chromium.googlesource.com/chromiumos/manifest.git # Optional: Make any changes to .repo/local_manifests/local_manifest.xml before syncing repo sync 创建chromiumos 构建包 export BOARD=amd64-generic cros_sdk -- ./build_packages --board=${BOARD} 构建镜像 cros_sdk -- ./build_image --board=${BOARD} 烧入USB 键入 sudo fdisk -l 查看插入U盘所在区域，然后执行如下操作烧录编译的系统到U盘\ncros_sdk -- cros flash usb:///dev/sdd ~/chromiumos/src/build/images/amd-generic/latest/chromiumos_test_image.bin 修改分区 如果要使用自定义大小容量的分区构建镜像，请考虑在 build_library/legacy_disk_layout.json 中添加新的磁盘布局或使用 adjust_part。请参阅下面的帮助，\nadjust_part ='STATE：1G' ---- 将1GB添加到状态分区 adjust_part ='ROOT-A：-1G' ---- 从主rootfs分区中删除1GB adjust_part ='STATE：= 1G' --- 设置状态分区为1GB 这里键入 cros_sdk -- ./build_image --board=${BOARD} --noenable_rootfs_verification test --adjust_part='STATE:+10G'，这样我们的Chromium OS用户空间便增加10G，如果使用默认设置你会发现用户空间容量不足（约140MB）\n最后 修改要安装到目标机器的bios启动项为U盘启动，插入U盘，启动。\n进入系统，按Ctrl + Alt + Back（F2）。在提示符下输入chronos并使用以下命令进行安装。\n/usr/sbin/chromeos-install ","description":"","tags":["ChromiumOS","archlinux"],"title":"Chromium OS源码编译、U盘安装及使用笔记","uri":"/posts/chromium-os-install/"},{"categories":null,"content":" 最近更新系统，内核从4.15 更新到了 4.16.9发现原来的无线模块编译不通过，找不到头文件stdarg.h\n 查看无线驱动信息 通过ip l可以看到只有有线网卡\n 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: enp3s0: \u003cBROADCAST,MULTICAST\u003e mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether 8c:16:45:3f:68:0d brd ff:ff:ff:ff:ff:ff 查看无线网卡驱动，找到相应的驱动去下载就好了\nlspci | grep -i 'newwork' Network controller: Realtek Semiconductor Co., Ltd. RTL8821CE 802.11ac PCIe Wireless Network Adapter 下载无线驱动源码 git clone https://github.com/endlessm/linux 由于这个项目特别的大，这里只需要下载drivers/net/wireless/rtl8821ce\n编译 修改Makefile 这里需要修改Makefile中TopDIR变量的值为当前路径，否则会提示错误退出\ncd drivers/net/wireless/rtl8821ce sed -i 's/export TopDIR ?=/export TopDIR ?= $(shell pwd)/g' Makefile 执行make 在最新的内核版本（4.16.9-1-ARCH）下编译失败，提示如下：\ngraz@graz ~/Source/driver_net_wireless/rtl8821ce % make /usr/bin/make ARCH=x86_64 CROSS_COMPILE= -C /lib/modules/4.16.9-1-ARCH/build M=/home/graz/Source/driver_net_wireless/rtl8821ce modules make[1]: Entering directory '/usr/lib/modules/4.16.9-1-ARCH/build' CC [M] /home/graz/Source/driver_net_wireless/rtl8821ce/core/rtw_cmd.o In file included from ./include/linux/list.h:9, from ./include/linux/module.h:9, from /home/graz/Source/driver_net_wireless/rtl8821ce/include/basic_types.h:81, from /home/graz/Source/driver_net_wireless/rtl8821ce/include/drv_types.h:31, from /home/graz/Source/driver_net_wireless/rtl8821ce/core/rtw_cmd.c:22: ./include/linux/kernel.h:6:10: fatal error: stdarg.h: No such file or directory #include \u003cstdarg.h\u003e ^~~~~~~~~~ compilation terminated. 通过locate stdarg.h找到头文件 “/usr/lib/gcc/x86_64-pc-linux-gnu/8.1.0/include/stdarg.h”\nln -s /usr/lib/gcc/x86_64-pc-linux-gnu/8.1.0/include/stdarg.h include/ 软链接创建好后，就可以执行make编译成功\n安装 sudo make install modprobe 8821ce 最后，没有报错的话，通过ip l 就可以找到这个无线网卡了\n1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: enp3s0: \u003cBROADCAST,MULTICAST\u003e mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether 8c:16:45:3f:68:0d brd ff:ff:ff:ff:ff:ff 3: wlp5s0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP mode DORMANT group default qlen 1000 link/ether 70:c9:4e:d8:6d:01 brd ff:ff:ff:ff:ff:ff ","description":"","tags":["rtl8821ce","linux"],"title":"Arch Linux 内核更新 修复无线模块rtl8821ce编译失败的问题","uri":"/posts/kernel-upgrade-fix-rtl8821ce/"},{"categories":null,"content":"备份Ghost 后台export，导出后是一个JSON，包含所有文章以及一些元数据：修改日期、Tags 等等\n图片等资源，可以到 assets 文件夹下，打包下载\ncd /data/www/ghost tar -zcvf images.tag assets/content 安装hexo 安装依赖 pacman -S npm 安装 npm install hexo-cli -g cd /data/www/ hexo init hcaijin.com cd hcaijin.com hexo install hexo server 迁移 导入Ghost数据 ## 安装数据转换插件 npm install hexo-migrator-ghost --save ## 导入数据 hexo migrate ghost ghost-export.json 导入图片 cp images.tag /data/www/hcaijin.com/source/ cd /data/www/hcaijin.com/source/ tar -zxvf images.tag 最后，做一些必要的配置 基本配置  Hexo 配置 NexT 配置 NexT 高级配置  安装其他插件 npm install hexo-generator-searchdb --save npm install hexo-generator-sitemap --save npm install hexo-generator-feed --save npm install hexo-pwa --save npm install hexo-all-minifier --save ","description":"","tags":["hexo","ghost"],"title":"博客系统从ghost 迁移hexo 安装与配置","uri":"/posts/hexo-install/"},{"categories":null,"content":"if contact me : send_email(\"hcjonline@gmail.com\") ","description":"","tags":null,"title":"about","uri":"/about/"},{"categories":null,"content":"好久没有更新ghost 0.6.0，今天更新的时候发现最新版本，0.11.11 版本 更新安装的时候报错。\n查看error日志，是依赖的npm和node版本问题。解决方法就是要么升级npm,node，要么降级ghost到npm,node支持的版本。\n  升级npm,node在这里就不说了，网上有很多的方法，我用的是搬瓦工家的最便宜vps，使用的npm,node不好升级，估计还得升级linux内核，我就不打算使用这个方法了。\n  降级ghost到npm,node支持的版本。 我们到Ghost各版本历史去找一下历史版本，我尝试了几个版本，最后确定0.8.0这个版本是可以正常使用的。\n   这样我们就可以开始升级ghost了。升级ghost不需要停了当前的服务，但是，升级更新都要做好备份。\n 备份 登陆并进入https://$HOSTNAME/ghost/debug这个页面导出备份。\n最好能登陆到服务器进入ghost安装的目录备份一下根目录下的content，这一步要先暂停服务。\ncd /data/www/ghost tar -zcvf ghost-content.tag content  备份好以后，我们就可以删除与升级相关的目录了文件。\n rm -rf core/ node_modules/ index.js *.json 下载最新版本 curl -LOk https://github.com/TryGhost/Ghost/releases/download/0.8.0/Ghost-0.8.0.zip 然后解压到/data/www/ghost\ncd ~ unzip -uo Ghost-0.8.0.zip -d /data/www/ghost 安装并重启 npm cache clear \u0026\u0026 npm install --production 没有报错的话就是安装成功了。\n重启ghost\nNODE_ENV=production pm2 start index.js --name \"ghost\" ","description":"","tags":["ghost"],"title":"ghost 更新记录","uri":"/posts/ghost-upgrade/"},{"categories":null,"content":"起因 使用的gentoo有半年没有更新系统了，原来用的好好的输入法，更新完以后，在其他的程序都可以正常使用fcitx。但是，在chrome,firefox（后来知道应该是GTK,QT相关的程序用了最新版导致的问题）就是用不了，网上也有很多人提问，也没有一个有效的解决方法。\n环境  Linux hcj-arch 4.4.39-1-lts #1 SMP Thu Dec 15 21:10:18 CET 2016 x86_64 GNU/Linu fcitx version: 4.2.9.1 Google Chrome 55.0.2883.87 Mozilla Firefox 50.1.0  检查 首先保证环境变量有设置，当然，如果其他程序都可以使用，那这个应该是没有问题的\nexport GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=@im=fcitx 主要的问题就是我们要用命令 fcitx-diagnose 查看fcitx的相关模块是不是有安装。（更无脑的方式就是把这个命令里显示为红色的信息都看一遍，把相关的模块安装上就ok了）\n那么，我们可以看到： == 如上图所示，缺少gtk2,gtk3相关的模块支持，导致的Chrome,Firefox等gtk软件无法使用输入法的情况 ==\n解决 我们先看一下fcitx构建时用到的USE标记，以下 可以看到，我自己设置的是默认不安装gtk支持的，所以我们要加上，有以下两种方法：\n 可以直接在/etc/portage/make.conf USE标记上加上gtk的支持 直接定义USE标记，加上gtk的支持   USE=\"X autostart cairo dbus enchant introspection nls pango qt4 table xml -debug gtk2 gtk3 -lua -opencc -static-libs {-test}\" sudo emerge fcitx  最后，重新编译安装过fcitx以后，再看一下fcitx-diagnose，只要没有红色相关字体的警告信息，就说明已经可以正常使用了。把浏览器重启一下，如果还不行，得重启一下系统。\n ","description":"","tags":["linux","chrome","firefox","fcitx"],"title":"Linux 系统Chrome,Firefox程序无用使用Fcitx的问题解决方法","uri":"/posts/linux-%E7%B3%BB%E7%BB%9Fchrome-firefox%E7%A8%8B%E5%BA%8F%E6%97%A0%E7%94%A8%E4%BD%BF%E7%94%A8fcitx%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"categories":null,"content":" 最近想在virtualbox下安装Mac系统，了解到Mac的安装镜像文件是dmg格式的，并下载到了 Install OS X Yosemite 10.10.1.dmg 安装包。\n 解压缩 本来以为Mac的安装与其他系统的类似，只要把镜像包在虚拟机中做为cd启动就可以了，然而并没什么用 - -\n这不，想到把dmg格式的包转化为iso的格式再在虚拟机中启动，这就有了这篇文章的问题了。\ngoogle到这个工具acetoneiso可以直接把dmg格式的转为iso\n但是，我想是不是可以用更简单的方法来操作。 现在的dmg一般都使用(zlib 或者 bzip2压缩算法)压缩过\n需要使用dmg2img把dmg文件转为img\n$ dmg2img Install\\ OS\\ X\\ Yosemite\\ 10.10.1.dmg yosemite.img 提示如，就表示成功了： Archive successfully decompressed as yosemite.img\n检查模块 在挂载之前我们要先确保hfsplus模块启用：\nlsmod | grep hfs 如果没有输出，就表示模块未启用，使用如下命令启用：\nmodprobe hfsplus 挂载 启用成功后，就可以用mount挂载img，这里我挂载失败，提示存在坏道，在这里才找到了解决的方法。\nmount -t hfsplus -o loop my.img /mnt/hfs mount: wrong fs type, bad option, bad superblock on /dev/loop0, missing codepage or helper program, or other error In some cases useful info is found in syslog - try dmesg | tail or so 问题处理 查询系统日志在最下面提示如下信息：\ndmesg | tail [2015609.436682] hfsplus: unable to find HFS+ superblock 解决方案：\n1.先用fdisk查询img扇区 可以看到它有两个设备*.img1,*.img2\n2.把img的文件挂载出来就得找到开始挂载的起始扇区，所以要设置一下offset的值， 这里offset=1259643×512，运行以下：\nsudo mount -t hfsplus -v -o loop,offset=644937216 yosemite.img /mnt/hfs 以上，就可以把镜像挂载到了目录/mnt/hfs下。\n","description":"","tags":["linux","mount","mac","virtualbox"],"title":"Linux挂载Mac系统下的dmg文件","uri":"/posts/linux%E6%8C%82%E8%BD%BDmac%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84dmg%E6%96%87%E4%BB%B6/"},{"categories":null,"content":"2016-05-11 16:36:25.799 [RMI TCP Connection(4)-127.0.0.1] ERROR org.springframework.web.context.ContextLoader - Context initialization failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroFilter' defined in file [/home/hcj/Work/data/ecerp-saas/Sources/ecerp/out/artifacts/ecerp_web_war_exploded/WEB-INF/classes/spring/applicationContext.xml]: Cannot resolve reference to bean 'securityManager' while setting bean property 'securityManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'securityManager' defined in file [/home/hcj/Work/data/ecerp-saas/Sources/ecerp/out/artifacts/ecerp_web_war_exploded/WEB-INF/classes/spring/applicationContext.xml]: Cannot resolve reference to bean 'shiroSubjectFactory' while setting bean property 'subjectFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroSubjectFactory': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private gy.erp.service.admin.SecurityMonitor gy.erp.shiro.ShiroSubjectFactory.securityMonitor; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'securityMonitor' defined in class path resource [spring-domain.xml]: Cannot resolve reference to bean 'sessionService' while setting bean property 'sessionService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sessionService': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Invalid registry store file /data/erp.guanyisoft.com/tomcat/ecerp-web.properties, cause: Failed to create directory /data/erp.guanyisoft.com/tomcat! at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:329) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:107) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1391) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1132) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:522) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org. java报错总要看异常信息，以上主要关键的地方列在这里：\n;nested exception is java.lang.IllegalArgumentException: Invalid registry store file /data/erp.guanyisoft.com/tomcat/ecerp-web.properties, cause: Failed to create directory /data/erp.guanyisoft.com/tomcat! idea tomcat 在启动web应用的时候会生成一个注册dubbo服务的文件，需要指定生成路径，以前项目都是默认生成在out文件里的吧，最近，不知道什么变动，需要手工在项目配置文件application.properties 指定一下：\ndubbo.registry.file = /home/hcj/Work/data/ecerp-web.properties ","description":"","tags":["java","tomcat","idea"],"title":"idea tomcat 启动web应用异常处理","uri":"/posts/idea-tomcat-%E5%90%AF%E5%8A%A8web%E5%BA%94%E7%94%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"},{"categories":null,"content":" 最近转Gentoo，一切安装就绪了，但是想使用youtube观看视频的时候，竟没有声音，估计又得折腾一下了。\n （Advanced Linux Sound Architecture，ALSA）是Linux中提供声音设备驱动的内核组件，用来代替原来的开放声音系统（Open Sound System，OSSv3）。\n 系统环境：Linux hcj.com 4.1.15-gentoo-r1 组件：alsa 前提：内核已经配置支持  硬件设备显示 lspci | grep -i audio 安装 euse -E alsa emerge --ask --changed-use --deep @world emerge --ask alsa-utils 启动声音服务 /etc/init.d/alsasound start rc-update add alsasound boot ###声音服务设置boot级别 列出设备名 cat /sys/class/sound/card*/id 配置默认设备 vi ~/.asoundrc 最后，别忘了重启一下。\n参考链接1\n参考链接2\n","description":"","tags":["linux","alsamixer"],"title":"Linux 声卡驱动问题","uri":"/posts/linux-%E5%A3%B0%E5%8D%A1%E9%A9%B1%E5%8A%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":" 新配了个ThinkPad E55c 安装Gentoo时无线网卡没能正确识别。网上查了一下是3.15内核版本之前还没有包含这个驱动，需要手动安装一下。但是我想说我安装的内核版本是4.1,而且也安装了linux-firmware固件，可是怎么就没有这个驱动呢 - - 暂时先不深究。\n  内核版本：Kernel: x86_64 Linux 4.1.15-gentoo-r1 网卡型号：RTL8723BE  确认网卡型号 lspci -k | grep Network 下载源码 git clone https://github.com/lwfinger/rtlwifi_new.git cd rtlwifi_new/ make \u0026\u0026 make install 手动加载模块 modprobe rtl8723be ## 手动加载rtl8723be模块 modinfo rtl8723be ## 查看模块详情 模块加载成功，使用lspci -k看一下,如果显示的是如下图说明无线网卡驱动安装成功： 最后ip addr show 可以看到对应的网卡设备了 自启动加载模块 cat /etc/conf.d/modules modules=\"rtl8723be\" 引用\n","description":"","tags":["linux","Gentoo","rtl8723be"],"title":"Gentoo安装RTL8723BE无线网卡驱动","uri":"/posts/gentoo%E5%AE%89%E8%A3%85rtl8723be%E6%97%A0%E7%BA%BF%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8/"},{"categories":null,"content":"远程仓库有master和dev分支 克隆代码 git clone \u003cgit url\u003e 查看所有分支 git branch --all  默认有了dev和master分支，所以会看到如下三个分支\n  master[本地主分支] origin/master[远程主分支] origin/dev[远程开发分支]  ==新克隆下来的代码默认master和origin/master是关联的，也就是他们的代码保持同步，但是origin/dev分支在本地没有任何的关联，所以我们无法在那里开发==\n创建本地关联origin/dev的分支 git checkout dev origin/dev 创建本地分支dev，并且和远程origin/dev分支关联，本地dev分支的初始代码和远程的dev分支代码一样\n切换到dev分支进行开发 git checkout dev # 这个是切换到dev分支，然后就是常规的开发 假设远程仓库只有mater分支 克隆代码 git clone \u003cgit url\u003e 查看所有分支 git branch --all  默认只有master分支，所以会看到如下两个分支\n  master[本地主分支] origin/master[远程主分支]  ==新克隆下来的代码默认master和origin/master是关联的，也就是他们的代码保持同步==\n创建本地新的dev分支 git branch dev # 创建本地分支 git branch # 查看分支 这时会看到master和dev，而且master上会有一个星号 这个时候dev是一个本地分支，远程仓库不知道它的存在 本地分支可以不同步到远程仓库，我们可以在dev开发，然后merge到master，使用master同步代码，当然也可以同步\n发布dev分支 发布dev分支指的是同步dev分支的代码到远程服务器\ngit push origin dev:dev # 这样远程仓库也有一个dev分支了 在dev分支开发代码 git checkout dev # 切换到dev分支进行开发  开发代码之后，我们有两个选择\n  第一个：如果功能开发完成了，可以合并主分支  git checkout master # 切换到主分支 git merge dev # 把dev分支的更改和master合并 git push # 提交主分支代码远程 git checkout dev # 切换到dev远程分支 git push # 提交dev分支到远程  第二个：如果功能没有完成，可以直接推送  git push # 提交到dev远程分支 == 注意：在分支切换之前最好先commit全部的改变，除非你真的知道自己在做什么 ==\n删除分支 git push origin :dev # 删除远程dev分支，危险命令哦  下面两条是删除本地分支\n git checkout master # 切换到master分支 git branch -d dev # 删除本地dev分支 progit.pdf 书籍格式和语言：中文、英文、PDF、ePub 下载地址：http://git-scm.com/book\n转载\n","description":"","tags":["git"],"title":"git常规使用","uri":"/posts/git%E5%B8%B8%E8%A7%84%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":" 透明代理指对客户端透明，客户端不需要进行任何设置就使用了网管设置的代理规则 创建\n /etc/ss-redir.json 本地监听 1080 运行ss-redir -v -c /etc/ss-redir.json NAT表配置脚本 基本配置\niptables -t nat -N SHADOWSOCKS # 在 nat 表中创建新链 iptables -t nat -A SHADOWSOCKS -p tcp --dport 23596 -j RETURN # 23596 是 ss 代理服务器的端口，即远程 shadowsocks 服务器提供服务的端口，如果你有多个 ip 可用,但端口一致，就设置这个 iptables -t nat -A SHADOWSOCKS -d 123.456.789.111 -j RETURN # 123.456.789.111 是 ss 代理服务器的 ip, 如果你只有一个 ss服务器的 ip，却能选择不同端口,就设置此条 iptables -t nat -A SHADOWSOCKS -d 0.0.0.0/8 -j RETURN iptables -t nat -A SHADOWSOCKS -d 10.0.0.0/8 -j RETURN iptables -t nat -A SHADOWSOCKS -d 127.0.0.0/8 -j RETURN iptables -t nat -A SHADOWSOCKS -d 169.254.0.0/16 -j RETURN iptables -t nat -A SHADOWSOCKS -d 172.16.0.0/12 -j RETURN iptables -t nat -A SHADOWSOCKS -d 192.168.0.0/16 -j RETURN iptables -t nat -A SHADOWSOCKS -d 224.0.0.0/4 -j RETURN iptables -t nat -A SHADOWSOCKS -d 240.0.0.0/4 -j RETURN iptables -t nat -A SHADOWSOCKS -p tcp -j REDIRECT --to-ports 1080 # 1080 是 ss-redir 的监听端口,ss-local 和 ss-redir 的监听端口不同,配置文件不同 最后是应用上面的规则,将OUTPUT出去的tcp流量全部经过SOCKS链\n #如果是在openwrt上实现透明代理的话,使用下面被注释了的规则 iptables -t nat -I PREROUTING -p tcp -j SHADOWSOCKS # 在 PREROUTING 链前插入 SHADOWSOCKS 链,使其生效 在个人电脑上使用以下配置 iptables -t nat -A OUTPUT -p tcp -j SHADOWSOCKS 如果要过滤国内流量可以 列表太长了就不列出来了！\n清除自定义规则 清空整个链 iptables -F 链名,比如:\niptables -t nat -F SHADOWSOCKS 删除指定的用户自定义链 iptables -X 链名 比如:\niptables -t nat -X SHADOWSOCKS 从所选链中删除规则 iptables -D 链名 规则详情 比如:\niptables -t nat -D SHADOWSOCKS -d 223.223.192.0/255.255.240.0 -j RETURN 解决DNS污染的问题 $ sudo pacman -S archlinuxcn/dnsmasq-china-list-git $ sudo dnsmasq-update-china-list 114 ####脚本如下： #!/bin/bash case \"$1\" in 114) DNS=114.114.114.114 ;; ali) DNS=223.5.5.5 ;; cnnic) DNS=1.2.4.8 ;; baidu) DNS=180.76.76.76 ;; google) DNS=8.8.8.8 ;; *) DNS=$1 esac sed -i \"s|^\\(server.*\\)/[^/]*$|\\1/$DNS|\" /etc/dnsmasq.d/accelerated-domains.china.conf ","description":"","tags":["iptables","shadowsocks"],"title":"ss-redir 的 iptables 配置(透明代理)","uri":"/posts/ss-redir-%E7%9A%84-iptables-%E9%85%8D%E7%BD%AE-%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86/"},{"categories":null,"content":" 工作中，同事之间拷贝数据的时候，由于我用的linux系统无法识别同事的NTFS移动硬盘，这才网上查了一下，原来还得安装一个软件，以下是转载的文章,记录一下。\n  有时候做大数据量迁移时，为了快速迁移大数据，有可能在Linux服务器上临时挂载NTFS格式的移动硬盘， 一般情况下，Linux是识别不了NTFS格式移动硬盘的（需要重编译Linux核心才能，加挂NTFS分区），这时候为了能让Linux服务器能够识别NTFS的移动硬盘，就必须安装ntfs-3g（Third Generation Read/Write NTFS Driver）的包。\n NTFS-3G介绍 NTFS-3G是一个开源项目，NTFS-3G是为Linux, Android, Mac OS X, FreeBSD, NetBSD, OpenSolaris, QNX, Haiku,和其他操作系统提供的一个稳定的，功能齐全，读写NTFS的驱动程序的。它提供了安全处理Windows XP，Windows Server 2003，Windows 2000，Windows Vista，Windows Server 2008和Windows 7操作系统下的NTFS文件系统。\nNTFS-3g是一个开源软件，它支持在Linux下面读写NTFS格式的分区。它非常的快速，同时也很安全。它支持Windows 2000、XP、2003和Vista，并且支持所有的符合POSIX标准的磁盘操作。 ntfs-3g的目的是为了持续的发展，各硬件平台和操作系统的用户需要可靠的互通与支持ntfs的驱动，ntfs-3g可以提供可信任的、功能丰富的高性能解决方案。经过了12年多的发展，ntfs-3g已经逐渐稳定；\n 资料介绍\n  官方网址：http://www.tuxera.com/， 文档手册：http://www.tuxera.com/community/ntfs-3g-manual/ 下载地址：http://www.tuxera.com/community/ntfs-3g-download/  安装 解压安装NTFS-3G。 tar -xvzf ntfs-3g_ntfsprogs-2012.1.15.tgz　cd ntfs-3g_ntfsprogs-2012.1.15 ./configure make make install 如果没有报错，提示安装成功，下面就可以用ntfs-3g来实现对NTFS分区的读写了\n配置 配置挂载NTFS格式的移动硬盘 首先得到NTFS分区的信息 $ sudo fdisk -l | grep NTFS /dev/sdc1 * 1 244 1955776+ 7 HPFS/NTFS 设置挂载点，用如下命令实现挂载 mount -t ntfs-3g \u003cNTFS Partition\u003e \u003cMount Point\u003e  例如得到的NTFS分区信息为/dev/sdc1，挂载点设置在/mnt/usb下:\n $ mount -t ntfs-3g /dev/sdc1 /mnt/usb ########## 或者直接用 ####### $ ntfs-3g ntfs-3g /dev/sdc1 /mnt/usb 如果想实现开机自动挂载，可以在/etc/fstab里面添加如下格式语句 \u003cNTFS Partition\u003e \u003cMount Point\u003e ntfs-3g silent,umask=0,locale=zh_CN.utf8 0 0 ==这样可以实现NTFS分区里中文文件名的显示。 ==\n　卸载分区 $ umount \u003cNTFS Partition\u003e ##### 或者 ##### $ umount \u003cMount Point\u003e ","description":"","tags":["linux","ntfs"],"title":"Linux系统挂载NTFS移动硬盘","uri":"/posts/linux%E7%B3%BB%E7%BB%9F%E6%8C%82%E8%BD%BDntfs%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98/"},{"categories":null,"content":" 再一次捣鼓gentoo,还是遇到了相当多的麻烦，这里把安装的方法重新在blog里整理一下，跟着官方安装步骤一点点来。\n 准备安装之前 下载gentoo所需的引导镜像和系统文件压缩包 下载地址： https://www.gentoo.org/downloads/\n主要文件：\n install-amd64-minimal-20160303.iso portage-latest.tar.bz2 stage3-amd64-20160303.tar.bz2  $ mkdir gentoo/ \u0026\u0026 cd gentoo/ $ wget -c # http://mirrors.163.com/gentoo/releases/amd64/autobuilds/20160303/install-amd64-minimal-20160303.iso $ wget -c http://mirrors.163.com/gentoo/snapshots/portage-latest.tar.bz2 $ wget -c http://mirrors.163.com/gentoo/releases/amd64/autobuilds/20160303/stage3-amd64-20160303.tar.bz2 U盘准备 插入U盘，查看U盘设备名,不需求挂载\n$ lsblk $ sudo dd if=install-amd64-minimal-20160303.iso of=/dev/sdb 这样，就制作好了U盘启动了，把U盘插入要安装的机子，配置BIOS通过U盘启动，就可以进入光盘引导的临时系统。\n开始安装 配置临时系统  安装gentoo最主要是先把网络配置好，这里我安装的时候遇到了个非常郁闷的问题，就是，公司的个别网段限制下载，导致我在配置网络的时候浪费了不少时间，所以最好先确认一下，你所在的网段是否可以使用wget下载文件。\n 配置IP 通常启动U盘临时系统应该可以dhcp分配到一个ip,但是我因为是公司的网络，所以最好手动配置一下\n# ip addr add 192.168.3.155/24 dev enp0s25 # ip route add default via 192.168.3.1 dev enp0s25 # echo \"192.168.1.1\" \u003e /etc/resolv.conf 配置ssh链接 为了方便，最好远程链接到临时系统下，那么就得配置sshd服务。\n==Tip: 最新的sshd服务器默认限制root登陆，需要修改一下/etc/ssh/sshd_config 配置PermitRootLogin 为 yes==\n# /etc/init.d/sshd start # passwd root ####配置root用户密码 以上，我们就可以到本机，使用ssh远程登陆这个U盘挂启的临时系统了\n安装到硬盘上 系统分区fdisk # fdisk -l Device Boot Start End Sectors Size Id Type /dev/sda1 2048 6143 4096 2M ef EFI (FAT-12/16/32) /dev/sda2 6144 268287 262144 128M 83 Linux /dev/sda3 268288 17045503 16777216 8G 82 Linux swap / Solaris /dev/sda4 17045504 937703087 920657584 439G 5 Extended /dev/sda5 17047552 226762751 209715200 100G 83 Linux /dev/sda6 226764800 937703087 710938288 339G 83 Linux # fdisk /dev/sda 使用fdisk分区以前有详细的说明过，在这里就不再说了。不懂的，请写看一下这个 树莓派安装Gentoo Linux 1.1.3 节\n也可以参照 官方分区方案\n重新读取sda分区表: # partx -a /dev/sda 格式化分区为文件系统 # mkfs.ext2 /dev/sda2 # mkfs.ext4 /dev/sda5 # mkfs.ext4 /dev/sda6 格式化swap分区并激活 # mkswap /dev/sda3 # swapon /dev/sda3 创建系统临时挂载点 # mount /dev/sda5 /mnt/gentoo # mkdir -p /mnt/gentoo/{boot,home,} # mount /dev/sda2 /mnt/gentoo/boot # mount /dev/sda6 /mnt/gentoo/home 设定日期和时间 安装Gentoo之前，请确保日期和时间是否正确设置。错误配置的时钟可能会产生各种奇怪的错误！==主要==！！！\n要验证当前日期和时间，运行日期：\n# date Sat Mar 5 16:26:08 UTC 2016 如果时间不对，请使用 MMDDhhmmYYYY 这样的格式配置一下日期和时间\ndate 030516262016 下载和解压相关包 使用临时系统自带的links下载stage3和portage ==Tip: 如果前面已经在本机下载过了可以跳过这一步==\n# links https://www.gentoo.org/downloads/mirrors/ 或者配置代理下载：\n# links -http-proxy proxy.server.com:8080 https://www.gentoo.org/downloads/mirrors/ 效验下载的文件 效验下载的文件是否完整，打开 .DIGESTS(.asc) 相关文件对比sha512加密的是否一至。\n# openssl dgst -r -sha512 stage3-amd64-20160303.tar.bz2 解压stage3和portage 把下载好的stage3和portage放到/mnt/gentoo目录下，进入目录解压：\n# cd /mnt/gentoo/ # tar xvjpf stage3-*.tar.bz2 --xattrs ==注: stage3解压的文件是Gentoo的目录结构，所以要解压到临时的系统目录下,即/mnt/gentoo，方便后面进行chroot==\n下面解压portage，这个解压需要一点时间。\n# tar jxvf portage-latest.tar.bz2 -C /mnt/gentoo/usr ==注: portage-latest.tar.bz2解压的文件为系统软件目录结构,需要解压到/mnt/gentoo/usr目录下==\n安装基本gentoo系统 配置portage make 参数  配置了MAKEOPTS为cpu核心数+1 配置就近的镜像地址 GETOO_MIRRORS 为厦门大学的镜像源  # cat /etc/mnt/gentoo/etc/portage/make.conf ==Tip: 参数配置文件/mnt/gentoo/usr/share/portage/config/make.conf.example ==\n配置主要Gentoo的存储库 # mkdir /mnt/gentoo/etc/portage/repos.conf # cp /mnt/gentoo/usr/share/portage/config/repos.conf /mnt/gentoo/etc/portage/repos.conf/gentoo.conf 配置chroot环境的dns 只需要把livecd临时环境的resolv.conf复制到要chroot的目录里就好了，如下：\ncp -L /etc/resolv.conf /mnt/gentoo/etc/ 挂载必要的文件系统 # mount -t proc proc /mnt/gentoo/proc # mount --rbind /sys /mnt/gentoo/sys # mount --make-rslave /mnt/gentoo/sys # mount --rbind /dev /mnt/gentoo/dev # mount --make-rslave /mnt/gentoo/dev Chroot 到新的环境 # chroot /mnt/gentoo /bin/bash # source /etc/profile # export PS1=\"(chroot) $PS1\" 设置主机名 这不是必要的步骤\n# sed -i -e 's/hostname.*/hostname=\"hcj.com\"/' /etc/conf.d/hostname # echo \"127.0.0.1 hcj.com localhost\" \u003e /etc/hosts 配置Portage # emerge-webrsync 我在配置这个的时候报错了，按照提示删除tmestamp.x文件即可。\n更新portage树\n# emerge --sync 小内存的情况使用静默模式\n# emerge --sync --quiet 配置系统环境 查看更新的通知\n# eselect news list # eselect news read 选择适合的配置\n# eselect profile list # eselect profile set 3 ### 我选择的是桌面环境系统 更新timezone\n# ls /usr/share/zoneinfo # echo \"Asia/Shanghai\" \u003e /etc/timezone # emerge --config sys-libs/timezone-data 配置语言编码\n# nano -w /etc/locale.gen # locale-gen # eselect locale list Available targets for the LANG variable: [1] C [2] POSIX [3] en_US [4] en_US.iso88591 [5] en_US.utf8 [6] zh_CN.utf8 * [ ] (free form) # eselect locale set 6 更新一下环境\n# env-update \u0026\u0026 source /etc/profile \u0026\u0026 export PS1=\"(chroot) $PS1\" 内核配置 安装内核源码 # emerge --ask sys-kernel/gentoo-sources # genkernel --install initramfs 配置fstab cat /etc/fstab 编译内核文件 genkernel all 完成以上就可以在/boot目录下看到内核文件\n# ls /boot/kernel* /boot/initramfs* ==注: genkernel编译出的内核支持几乎所有硬件，编译需要一段很长的时间，一旦genkernel运行完成，一个包括全部模块和initrd的内核将被建立。在后面配置引导程序时我们将会用到这个内核和initrd。请记下内核和initrd的名字，因为您将在配置引导程序的时候用到他们。initrd将会在启动真正的系统前自动识别硬件（如同安装光盘一样）==\n安装其他软件 # emerge vim ### 安装vim 方便后面的配置 # emerge syslog-ng ### 安装系统日志管理 # rc-update add sysklogd default # emerge logrotate ### 日志格式化工具 # emerge --ask sys-process/cronie ### 计划任务系统 # rc-update add cronie default # emerge --ask net-misc/dhcpcd # emerge --ask sys-apps/mlocate ### 快速索引 配置网络 # cat /etc/conf.d/net config_enp0s25=\"192.168.3.155 netmask 255.255.255.0 brd 192.168.3.255\" routes_enp0s25=\"default via 192.168.3.1\" # ln -s /etc/init.d/net.lo /etc/init.d/net.enp0s25 # rc-update add net.enp0s25 default # rc-update add sshd default 配置root用户密码 这是必要的，为了从新系统能进入\n# passwd 配置GRUB引导程序 # emerge --ask sys-boot/grub:2 # grub2-install /dev/sda # grub2-mkconfig -o /boot/grub/grub.cfg 最后重启一下系统 # exit # cd # umount -l /mnt/gentoo/dev{/shm,/pts,} # umount /mnt/gentoo{/boot,/sys,/proc,} # reboot 引用\n","description":"","tags":["linux","Gentoo"],"title":"Linux gentoo U盘安装指南","uri":"/posts/linux-gentoo-u%E7%9B%98%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/"},{"categories":null,"content":" 最近，在使用U盘安装gentoo配置sshd服务端碰到了问题，记录一下ssh服务端的配置文件。\n 关于 SSH Server 的整体设定，包含使用的 port 啦，以及使用的密码演算方式 Port 22　# SSH 预设使用 22 这个 port，您也可以使用多的 port ！ # 亦即重复使用 port 这个设定项目即可！ Protocol 2,1　# 选择的 SSH 协议版本，可以是 1 也可以是 2 ， # 如果要同时支持两者，就必须要使用 2,1 这个分隔了！ #ListenAddress 0.0.0.0　# 监听的主机适配卡！举个例子来说，如果您有两个 IP， # 分别是 192.168.0.100 及 192.168.2.20 ，那么只想要 # 开放 192.168.0.100 时，就可以写如同下面的样式： ListenAddress 192.168.0.100 # 只监听来自 192.168.0.100 这个 IP 的SSH联机。 # 如果不使用设定的话，则预设所有接口均接受 SSH PidFile /var/run/sshd.pid　# 可以放置 SSHD 这个 PID 的档案！左列为默认值 LoginGraceTime 600　# 当使用者连上 SSH server 之后，会出现输入密码的画面， # 在该画面中，在多久时间内没有成功连上 SSH server ， # 就断线！时间为秒！ Compression yes　# 是否可以使用压缩指令？当然可以啰！ 　说明主机的 Private Key 放置的档案，预设使用下面的档案即可！ HostKey /etc/ssh/ssh_host_key　# SSH version 1 使用的私钥 HostKey /etc/ssh/ssh_host_rsa_key　# SSH version 2 使用的 RSA 私钥 HostKey /etc/ssh/ssh_host_dsa_key　# SSH version 2 使用的 DSA 私钥 关于 version 1 的一些设定！ KeyRegenerationInterval 3600　# 由前面联机的说明可以知道， version 1 会使用 # server 的 Public Key ，那么如果这个 Public # Key 被偷的话，岂不完蛋？所以需要每隔一段时间 # 来重新建立一次！这里的时间为秒！ ServerKeyBits 768 # 没错！这个就是 Server key 的长度！ 关于登录文件的讯息数据放置与 daemon 的名称！ SyslogFacility AUTH　# 当有人使用 SSH 登入系统的时候，SSH会记录资 # 讯，这个信息要记录在什么 daemon name 底下？ # 预设是以 AUTH 来设定的，即是 /var/log/secure # 里面！什么？忘记了！回到 Linux 基础去翻一下 # 其它可用的 daemon name 为：DAEMON,USER,AUTH, # LOCAL0,LOCAL1,LOCAL2,LOCAL3,LOCAL4,LOCAL5, LogLevel INFO　# 登录记录的等级！嘿嘿！任何讯息！ # 同样的，忘记了就回去参考！ 安全设定项目！极重要！ 登入设定部分 PermitRootLogin no　# 是否允许 root 登入！最新版本的sshd配置默认是不允许使用root登陆的，如果要使用root登陆，要把no 改为 yes 。 UserLogin no　# 在 SSH 底下本来就不接受 login 这个程序的登入！ StrictModes yes　# 当使用者的 host key 改变之后，Server 就不接受联机， # 可以抵挡部分的木马程序！ RSAAuthentication yes　# 是否使用纯的 RSA 认证！？仅针对 version 1 ！ PubkeyAuthentication yes　# 是否允许 Public Key ？当然允许啦！只有 version 2 AuthorizedKeysFile .ssh/authorized_keys # 上面这个在设定若要使用不需要密码登入的账号时，那么那个 # 账号的存放档案所在档名！ 认证部分 RhostsAuthentication no　# 本机系统不止使用 .rhosts ，因为仅使用 .rhosts 太 # 不安全了，所以这里一定要设定为 no ！ IgnoreRhosts yes　# 是否取消使用 ~/.ssh/.rhosts 来做为认证！当然是！ RhostsRSAAuthentication no # 这个选项是专门给 version 1 用的，使用 rhosts 档案在 # /etc/hosts.equiv配合 RSA 演算方式来进行认证！不要使用 HostbasedAuthentication no # 这个项目与上面的项目类似，不过是给 version 2 使用的！ IgnoreUserKnownHosts no　# 是否忽略家目录内的 ~/.ssh/known_hosts 这个档案所记录 # 的主机内容？当然不要忽略，所以这里就是 no 啦！ PasswordAuthentication yes # 密码验证当然是需要的！所以这里写 yes 啰！ PermitEmptyPasswords no　# 若上面那一项如果设定为 yes 的话，这一项就最好设定 # 为 no ，这个项目在是否允许以空的密码登入！当然不许！ ChallengeResponseAuthentication yes # 挑战任何的密码认证！所以，任何 login.conf # 规定的认证方式，均可适用！ #PAMAuthenticationViaKbdInt yes # 是否启用其它的 PAM 模块！启用这个模块将会 # 导致 PasswordAuthentication 设定失效！ 　与 Kerberos 有关的参数设定！因为我们没有 Kerberos 主机，所以底下不用设定！ #KerberosAuthentication no #KerberosOrLocalPasswd yes #KerberosTicketCleanup yes #KerberosTgtPassing no 底下是有关在 X-Window 底下使用的相关设定！ X11Forwarding yes #X11DisplayOffset 10 #X11UseLocalhost yes 登入后的项目： PrintMotd no # 登入后是否显示出一些信息呢？例如上次登入的时间、地点等 # 等，预设是 yes ，但是，如果为了安全，可以考虑改为 no ！ PrintLastLog yes　# 显示上次登入的信息！可以啊！预设也是 yes ！ KeepAlive yes　# 一般而言，如果设定这项目的话，那么 SSH Server 会传送 # KeepAlive 的讯息给 Client 端，以确保两者的联机正常！ # 在这个情况下，任何一端死掉后， SSH 可以立刻知道！而不会 # 有僵尸程序的发生！ UsePrivilegeSeparation yes # 使用者的权限设定项目！就设定为 yes 吧！ MaxStartups 10　# 同时允许几个尚未登入的联机画面？当我们连上 SSH ， # 但是尚未输入密码时，这个时候就是我们所谓的联机画面啦！ # 在这个联机画面中，为了保护主机，所以需要设定最大值， # 预设最多十个联机画面，而已经建立联机的不计算在这十个当中 关于使用者抵挡的设定项目： DenyUsers *　# 设定受抵挡的使用者名称，如果是全部的使用者，那就是全部 # 挡吧！若是部分使用者，可以将该账号填入！例如下列！ DenyUsers test DenyGroups test　# 与 DenyUsers 相同！仅抵挡几个群组而已！ 关于 SFTP 服务的设定项目！ Subsystem sftp /usr/lib/ssh/sftp-server 　基本上，在您的系统中，『除非有必要，否则请不要更改 /etc/ssh/sshd_config 这个档案的设定值！』因为预设的情况下通常都是最严密的 SSH 保护了，因此，可以不需要更动他！上面的说明仅是在让大家了解每个细项的一些基本内容而已！需要注意的是最后一项，如果您不愿意开放 SFTP 的话，将最后一行批注掉即可！ ","description":"","tags":["linux","sshd","ssh"],"title":"ssh 服务端配置","uri":"/posts/ssh-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"转自http://blog.sae.sina.com.cn/archives/3003\n 这里给大家分享一些很有用的 Git 命令，其中很多用法你可能都不知道，无论你是工作在团队环境中或在您的个人项目中，这些命令将对你帮助很大，让你可以更加高效的进行项目开发，更轻松愉快的工作和生活。\n 导出最后一次提交修改过的文件 我一直在使用这个命令定期进行发送给其他人进行审查/整合。这条命令将把近期提交的修改过的文件导出到一个zip文件。\ngit archive -o ../updated.zip HEAD $(git diff --name-only HEAD^) 导出两次提交之间修改过的文件 同样，如果你需要导出两次提交之间修改过的文件，你可以用这一个。\ngit archive -o ../latest.zip NEW_COMMIT_ID_HERE $(git diff --name-only OLD_COMMIT_ID_HERE NEW_COMMIT_ID_HERE) 克隆一个特定的远程分支 如果你想从远程仓库克隆特定的一个分支，这条命令对你很有用：\ngit init git remote add -t BRANCH_NAME_HERE -f origin REMOTE_REPO_URL_PATH_HERE git checkout BRANCH_NAME_HERE 从无关的本地仓库应用补丁 如果您需要申请从提交的一些其他不相关的创库到本地存储库，这里是一个快捷的方式：\ngit --git-dir=PATH_TO_OTHER_REPOSITORY_HERE/.git format-patch -k -1 --stdout COMMIT_HASH_ID_HERE| git am -3 -k 检查您的分支变化是是否其他分支的一部分 cherry 命令可以让你检查你的分支的变化是否存在于其他一些分支之中。它会显示在当前分支相对于给定的分支的修改，用+或-标志提示提交合并与否。+表示不存在，而-表示存在于给定的分支。\ngit cherry -v OTHER_BRANCH_NAME_HERE #For example: to check with master branch git cherry -v master 启动一个无历史的新分支 有时候，你需要启动一个新的分支，同时想摒弃历史信息，例如，你想将代码放在公共领域（开源）又不想共享历史信息。\ngit checkout --orphan NEW_BRANCH_NAME_HERE 在不切换分支的情况下从其它分支检出文件 下面的命令是从其他分支获取文件，而不用切换分支。\ngit checkout BRANCH_NAME_HERE -- PATH_TO_FILE_IN_BRANCH_HERE 忽略跟踪文件的修改 如果你工作在一个团队，他们都是工作在同一个分支，你需要频繁的读取/合并文件。但是有时复位了你环境的特定配置，你必须在合并后每一次都再改一下。使用这个命令，你可以忽略更改特定的文件：\ngit update-index --assume-unchanged PATH_TO_FILE_HERE 检查提交的修改是否发布版本的一部分 这个 name-rev 命令可以告诉你提交相对于最新发布版本的位置。利用这一点，你可以检查你的变化是否发布版本的一部分。\ngit name-rev --name-only COMMIT_HASH_HERE 使用 pull rebase 操作替代 merge 如果你工作的团队正工作在同一个分支，那么你所要做的获取/合并或经常拉取。分支合并的 git 记录与合并提交时提示功能分支被并入主干。但在多个团队成员工作的同一分支的情况下，经常合并导致在日志中多个合并的消息引起混乱。所以你可以使用 pull rebase，以保持历史信息清除了无用合并的消息。\ngit config branch.BRANCH_NAME_HERE.rebase true 此外，您可以配置一个特定的分支总是衍合：\ngit pull --rebase ","description":"","tags":["linux","git"],"title":"10个很有用的 Git 命令（转）","uri":"/posts/10%E4%B8%AA%E5%BE%88%E6%9C%89%E7%94%A8%E7%9A%84-git-%E5%91%BD%E4%BB%A4%E8%BD%AC/"},{"categories":null,"content":" 首先，以前是写php的，从未接触java的开发。最近公司项目重组，被安排说去做java开发，而且要快速上手,安排培训，可是，培训的都是windows下的IDE开发配置。没办法，Google呗。这样就有了这篇东拼西奏的文章，也有自己的一些经验总结，没少碰壁，不过这里还是感谢同事的帮忙，让我对java的运行有了清晰的认识。\n 了解java包运行原理 java是编译型语言，自然少不了打包，链接，当然这些都可以用maven来管理。用maven打包，链接生成的安装包就是可以直接使用java来运行的，我们这里主要说web服务的配置，所以少不了tomcat。使用tomcat来运行web项目包，就可以在浏览器端访问，java应用服务，这就是大致的过程。\n安装必要的软件包 安装jdk,至于安装哪个版本，视情况而定 sudo pacman -S jdk8-openjdk 可以搜索一下\npacman -Ss java 安装maven sudo pacman -S maven 以上安装成功了以后，我们就可以使用java, mvn  的命令了，由于我们使用的是pacman安装方法，必要的环境变量都已经默认好了，可以不需要配置，具体可以看我以前写的 Java 学习笔记1\n安装tomcat，同样的源里也有多个版本，视情况安装相应的版本 sudo pacman -S tomcat7 tomcat 主要配置详解 主要目录功能 默认情況 tomcat7 安装路径为 /usr/share/tomcat7，这里罗列一下主要目录的作用：\n /usr/share/tomcat7： 程序的主目录，也是变量 $CATALINA_HOME 所指向的位置，在单 tomcat 实例的情況下，也是变量 $CATALINA_BASE 所指向的位置。 /usr/share/tomcat7/bin： 程序的执行脚本目录 conf -\u003e /etc/tomcat7： 配置文档目录，存放主要是配置信息。 lib -\u003e /usr/share/java/tomcat7： 共用jar包目录，这些包即给 tomcat 使用，也能给 web 应用程序所调用。 logs -\u003e /var/log/tomcat7： 日志目录，对于查找错误以及查看访问记录很有用。 webapps -\u003e /var/lib/tomcat7/webapps： 默认的 web 应用程序目录，tomcat7 自带了几个示例应用。  启动关闭脚本 我们进入程序执行脚本目录\ncd /usr/share/tomcat7 sudo ./startup.sh 以上，tomcat服务就启动成功了，可以在浏览器中访问http://localhost:8080 ，如果看到 tomcat 猫即说明服务已经安装成功并且能正常运行了。\nsudo ./shutdown.sh 这两个脚本都是通过调用 catalina.sh 来执行的，具体自己看脚本代码。\n实例讲解tomcat启动java应用 这里我犯了一个错误，总以为java应用之前总得有个相互调用的关系，没想到其实都已经在maven打包，安装到本地就行了，web应用配置好相应的pom.xml就可以调用maven打包，安装好的后台java应用。\n然后，我们开始说明代码部署过程：\ncd /data/app/ ###进入工程主目录 git clone git@erp:ecerp-saas ###从erp服务器拉代码到本地 cd /data/app/ecerp-saas/ ###进入代码目录 git pull ###这个是同步服务器代码 cd /data/app/ecerp-saas/Sources/ecerp ###进到主要工程目录 mvn clean install -Dmaven.test.skip=true ###打包安装工程目录下相应的程序，这样就会编译好应用到本地用户目录下`~/.m2/` 在web目录下新建目录erp.hcj.com\ncd /data/www/ mkdir erp.hcj.com/ cd erp.hcj.com/ web应用java环境变量配置\ntouch webconfig cat webconfig source /data/www/erp.hcj.com/webconfig ###使用环境变量生效 创建备份目录,当然这个不是必要的。\ntheday=$(date +%Y%m%d) releaseDir=\"/data/deployment/packages/${theday}\" if [ ! -e $releaseDir ] then mkdir -p $releaseDir fi 然后，我们就可以到java应用安装目录下找packagename，把它移到备份目录\ncp -fp `find ~/.m2/repository/ -name $packagename` $releaseDir/$packagename #备份数据 bktime=$(date +%y%m%d%H%M) backupdir=\"/data/deployment/release-backup/$bktime/$(basename $srvdir)\" if [ ! -e $backupdir ] then mkdir -p $backupdir fi rootdir=/data/www/erp.hcj.com/webroot for files in $(ls $rootdir) do if [ $files == \"upload\" ]; then ¦ echo $files not backup else ¦ /bin/cp -rfp $rootdir/$files $backupdir fi done ### 删除旧应用 rm -rf $rootdir/WEB-INF/* ### 解压文件，在web主目录下生成webroot packagefile=$releaseDir/$packagename tar zxf $packagefile -C /data/www/erp.hcj.com ### 修改webroot的权限 chown tomcat7.tomcat7 -R /data/www/erp.hcj.com/webroot 以上就基本是把java打包的应用程序，安装到了tomcat的webroot目录下了，但是要使这个应用启动成功，还需要配置多实例的tomcat的配置文件server.xml\ncd /data/www/erp.hcj.com mkdir -p tomcat/{conf,logs,tmp,work,} cp -r /etc/tomcat7/* tomcat/conf/ sudo chown -R tomcat7.tomcat7 tomcat/ vi server.xml 主要修改如下配置： ### 设置tomcat环境变量 export CATALINA_HOME=\"/usr/share/tomcat7\" export DUSER=\"tomcat7\" export CATALINA_BASE=\"/data/www/erp.hcj.com/tomcat\" export CATALINA_PID=\"$CATALINA_BASE/tomcat.pid\" export CATALINA_TMPDIR=\"$CATALINA_BASE/tmp\" export CATALINA_OUT=\"$CATALINA_BASE/logs/catalina.out\" export LOCKFILE=\"$CATALINA_BASE/tomcat.lock\" ### 启动服务 /bin/bash $CATALINA_HOME/bin/startup.sh ### 关闭服务 /bin/bash $CATALINA_HOME/bin/shutdown.sh 参考\n","description":"","tags":["linux","java","tomcat"],"title":"Linux服务器配置java web服务总结","uri":"/posts/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEjava-web%E6%9C%8D%E5%8A%A1%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"镜像配置 由于maven的中央仓库位于国外，速度慢，也有可能其他原因无法访问，我们可以使用国内的镜像仓库。配置镜像仓库需要修改conf/settings.xml,打开该文件修改mirror标签如下：\nvim /opt/maven/conf/settings.xml maven仓库默认是放在用户目录的.m2隐藏目录下的 ~/.m2/repository/ 。如果需要将仓库迁移到其他目录，修改conf/settings.xml 环境变量 配置maven编译程序过程中可用的最大，最下内存，防止内存溢出。\nMAVEN_OPTS=\"-Xms256m -Xmx512m\" export MAVEN_OPTS  配置web服务一定要记得设置compressableMimeType  ","description":"","tags":["java","maven"],"title":"Java 学习笔记2","uri":"/posts/java-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/"},{"categories":null,"content":" 以下是在Arch Linux下操作，其他发行版或操作系统不适用。Maven这个词可以翻译为“知识的积累”，也可以翻译为“专 家”或“内行”。本文将介绍Maven这一跨平台的项目管理工具。作为Apache组织中的一个颇为成功的开源项目，Maven主要服务于基于Java平台的项目构建、依赖管理和项目信息管理。无论是小型的开源类库项目，还是大型的企业级应用；无论是传统的瀑布式开发，还是流行的敏捷模式，Maven都能大显身手。\n 安装java环境 sudo pacman -S jdk8-openjdk 安装好以后可以使用如下命令：\narchlinux-java help ##查看帮助 archlinux-java status ##java环境状态 使用的版本信息 安装maven 配置 maven 会被安装到/opt/maven/  目录下\nsudo pacman -S maven 修改环境变量\nvi ~/.bashrc 这样以后，就可以使用 mvn 命令来管理java项目，如下：\ncd /data/gyapp/ ###进入工作目录。(自定义) mvn archetype:generate -DgroupId=helloworld -DartifactId=helloworld -Dpackage=helloworld -Dversion=1.0-SNAPSHO 打包程序 执行了上面的命令会在当前工作目录生成helloworld项目目录。 cd helloworld/ mvn package 这个时候， maven 在 helloworld 下面建立了一个新的目录 target/ ，构建打包后的 jar 文件 helloworld-1.0-SNAPSHOT.jar 就存放在这个目录下。编译后的 class 文件放在 target/classes/ 目录下面，测试 class 文件放在 target/test-classes/ 目录下面。\n运行 为了验证我们的程序能运行，执行下面的命令：\njava -cp target/helloworld-1.0-SNAPSHOT.jar helloworld.App 输出源代码里的程序，显示 HelloWorld! 表示成功。\n第一个程序 vi HelloWorld.java 编译源代码，在当前目录生成HelloWorld.class,然后执行java HelloWorld\njavac HelloWorld.java java HelloWorld 重要 转换ppk成linux下面支持的密钥文件\nsudo pacman -S putty 安装putty以后，可以使用如下命令：\nputtygen git_cesi.ppk -o id_rsa.pub -O public-openssh puttygen git_cesi.ppk -o id_rsa -O private-openssh 参考\n","description":"","tags":["java","maven"],"title":"Java 学习笔记1","uri":"/posts/java-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"categories":null,"content":" 这里分享一个Linux服务器终端下发送消息的命令。由于平时工作中，必免不了与运维同事之间的信息交换，想到我们都是链的同一台服务器，这样就可以通过以下两个命令来发送消息。\n 给指定用户发送消息 首先，可使用w或who命令查看当前登录的用户信息； 然后，使用write命令将信息发送到用户的终端上，用法步骤如下：\n$ w 17:17:53 up 19 days, 57 min, 3 users, load average: 0.00, 0.01, 0.05 USER TTY LOGIN@ IDLE JCPU PCPU WHAT zq pts/0 14:19 1:50 0.08s 0.02s -bash hcaijin pts/1 10:30 55.00s 7:05 0.23s -bash hcaijin pts/2 17:17 1.00s 0.01s 0.00s w $ write hcaijin pts/1 Test send message. 然后使用hcaijin账号登录，且tty号为pts/1的登录用户终端会收到如下消息：\nMessage from hcaijin@hcj-arch on pts/2 at 17:18 ... Test send message. 给当前所有用户发送消息 给当前登录所有用户发送消息（需要root权限），使用wall（write all的缩写）\n$ wall 'Test send message to all user.' 执行wall命令，所有登录到该机器的控制台(console)界面上都会收到如上所示的消息。\n引用\n","description":"","tags":["linux","write","wall"],"title":"Linux 终端下发送消息命令","uri":"/posts/linux-%E7%BB%88%E7%AB%AF%E4%B8%8B%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":" 最近发现Linux 终端里有很多好玩的命令，这里记录一下，以免下次还得搜索 - -\n 一些好玩的命令 sl $ sl telnet $ telnet towel.blinkenlights.nl rev $ rev factor $ factor cowsay $ cowsay / cowthink fortune $ fortune / fortune-zh cmatrix $ cmatrix yes $ yes $ yes I love China yes 是一个非常有趣又有用的命令，尤其对于脚本编写和系统管理员来说，它可以自动地生成预先定义的响应或者将其传到终端。\ntoilet $ toilet hcaijin.com $ toilet -f mono12 -F metal hcaijin.com while $ while true; do echo \"$(date '+%D %T' | toilet -f term -F border --gay)\"; sleep 1; done espeak $ espeak \"Tecmint is a very good website dedicated to Foss Community\" 将你的多媒体音箱的音量调到最大，然后在将这个命令复制到你的终端，来看看你听到上帝的声音时的反应吧。\nfor for i in {1..19}; do for j in $(seq 1 $i); do echo -ne $i x $j=$((i*j))\\\\t;done; echo;done banner $ banner hcaijin.com 终端下有很多危险的命令，千万小心执行。 fork炸弹 这个命令其实是一个fork炸弹，它会以指数级的自乘，直到所有的系统资源都被利用了或者系统挂起\n$ :(){ :|:\u0026 }: rm 删除命令，一定要小心不可用root用户执行以下\n$ rm -rf / dd 很有用的命令，但是要注意不要运行以下命令，其实我也没有运行过- -\n$ dd if=/dev/zero of=/dev/mem shred 覆盖文件让它不能再读，传说中的文件粉碎机\n$ shred --help ","description":"","tags":["linux","bash"],"title":"Linux 下终端里好玩与危险命令汇总","uri":"/posts/linux-%E4%B8%8B%E7%BB%88%E7%AB%AF%E9%87%8C%E5%A5%BD%E7%8E%A9%E4%B8%8E%E5%8D%B1%E9%99%A9%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/"},{"categories":null,"content":" 由于 Arch Linux 采用滚动更新，最近php7.0也开始更新升级了，但是这会导致目前项目还是采用的mysql模块的程序来说真真是不适合升级的。所以，这里在网上查了一下降级安装的方法分享这里。\n 通过备份软件包降级安装 找到相应的php备份包，如果你最近没有执行 pacman -Scc以清空包缓存的话，应该在那儿)\nls -l /var/cache/pacman/pkg | grep php 如果在，你可以执行pacman -U ×××.pkg.tar.gz来安装旧版本。如果pacman提示文件冲突的话，你可以通过加上-f参数以强制执行，即\npacman -U --force ×××.pkg.tar.gz 这个过程会移除现有的包，仔细的计算所有依赖的改变，然后安装你选择的旧版本的软件包以及合适的依赖。\n通过downgrade程序来自动化降级安装软件包 在 AUR 中有一个包叫做downgradeAUR。它是一个简单的 Bash 脚本，它会从你的缓存中寻找旧版本的包，如果没有的话它会搜索 A.R.M.。你可以选择一个旧包来安装。它基本上自动化了上面所述的过程。查看 downgrade –help 获取使用方法的信息。\nsudo yaourt -S downgrade downgrade -s php ##搜索相关包版本 downgrade php ##降级安装包 如何恢复所有包到指定日期 如果想恢复所有包到指定日期（比如2014年3月30日），你必须如下例所示编辑 /etc/pacman.conf，从而让 pacman 保持在这个时间点并且直接使用指定的服务器：\n[core] SigLevel = PackageRequired Server=http://ala.seblu.net/repos/2014/03/30/$repo/os/$arch [extra] SigLevel = PackageRequired Server=http://ala.seblu.net/repos/2014/03/30/$repo/os/$arch [community] SigLevel = PackageRequired Server=http://ala.seblu.net/repos/2014/03/30/$repo/os/$arch 或者如下例编辑 /etc/pacman.d/mirrorlist：\n## ## Arch Linux repository mirrorlist ## Generated on 2042-01-01 ## Server=http://ala.seblu.net/repos/2014/03/30/$repo/os/$arch 然后同步包数据库以强制降级：\n# pacman -Syyuu 禁止指定包自动升级的方法 ==注意: 如果你改变了操作系统的一个基本的组件包，你也许需要降级许多包。这些软件包可能在过程中被删除，需要手动一点一点的安装回来；同时，后续升级时要小心，不要重新安装不想要的软件包版本。==\nsudo vim /etc/rc.conf 添加行\nIgnorePkg = php php-cgi php-gd\n这样子,我们就可以禁止上面的三个包自动升级了.如果有其它的包想禁止,直接添加就可以了,记住分隔符要用空格哦.\n参考文档1 参考文档2 引用\n","description":"","tags":["linux","archlinux","pacman"],"title":"Arch Linux 降级安装软件包与禁止自动升级指定软件包","uri":"/posts/arch-linux-%E9%99%8D%E7%BA%A7%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E5%8C%85%E4%B8%8E%E7%A6%81%E6%AD%A2%E8%87%AA%E5%8A%A8%E5%8D%87%E7%BA%A7%E6%8C%87%E5%AE%9A%E8%BD%AF%E4%BB%B6%E5%8C%85/"},{"categories":null,"content":"用如下命令查询出来结果中包含“ip地址=数量”的攻击者信息：\ncat /var/log/secure|awk '/Failed/{print $(NF-3)}'|sort|uniq -c|awk '{print $2\"=\"$1;}' 查看IP所在地：\ncurl ipinfo.io/{IP} curl cip.cc/{IP} 随机生成密码：\nfunction randpw32(){ \u003c /dev/urandom tr -dc '!@#$%^\u0026*'_A-Z-a-z-0-9 | head -c${1:-32};echo; } function randpw16(){ \u003c /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-16};echo; } Chromium 开启代理：\nfunction secure_chromium { port=1080 #使用以下两种配置都可以 #export SOCKS_SERVER=localhost:$port #export SOCKS_VERSION=5 #chromium \u0026 chromium --proxy-server=\"socks://localhost:$port\" \u0026 exit } ","description":"","tags":["linux","shell","bash"],"title":"Linux 服务器上相关脚本日志","uri":"/posts/linux-%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9B%B8%E5%85%B3%E8%84%9A%E6%9C%AC%E6%97%A5%E5%BF%97/"},{"categories":null,"content":" 今天修改Ghost密码，因为是粘贴复制，估计是粘贴到了其他字符，导致密码错误登陆后台失败。而且还因为登录尝试次数过多，造成用户被锁定，只能通过发送邮件找回密码，但是，我配置的Gmail邮箱被google限制使用收发邮件功能了应该，以后看一下具体的原因。\n 查找sqlite数据库用户信息 Ghost用的sqlite数据库，登陆到服务器，找到sqlite数据库，存放位置默认是在 Ghost 安装目录下的 content/data/ ，名称为ghost.db使用如下命令：\n$ cd /data/www/ghost/content/data/ $ sudo sqlite3 ghost.db sqlite\u003e .help ### 这里已经进到sqlite命令行模式下了，用\".help\"查看帮助 sqlite\u003e .tables ### 列表所有的表 sqlite\u003e .schema ### 列表所有表的结构 这里我们主要看users表 sqlite\u003e selete * from users; 到这里就可以列出后台登陆的会员信息了，仔细看一下发现有个status字段的值应该是locked; password字段值是一串使用 BCrypt Hash Generator 生成的密钥。\n修改密码为新生成的密钥 // 更新密码 这里的密码为 admin\nsqlite\u003e update users set password = \"$2a$10$ahse9xU.Tr9MttVX4tO1zOER7odgDrQuJzgjZI4fm56x84c/2dGqq\" where id = 1; ### 更新密码 sqlite\u003e update users set status = \"active\" where id = 1; ### 解锁用户 sqlite\u003e .quit 完成以上两步，就可以重新登录了。\n","description":"","tags":["ghost","sqlite"],"title":"Ghost博客手工修改管理员密码方法","uri":"/posts/ghost%E5%8D%9A%E5%AE%A2%E6%89%8B%E5%B7%A5%E4%BF%AE%E6%94%B9%E7%AE%A1%E7%90%86%E5%91%98%E5%AF%86%E7%A0%81%E6%96%B9%E6%B3%95/"},{"categories":null,"content":"Gentoo介绍 Gentoo的历史  Gentoo Linux （原来被称为 Enoch Linux ) 是在1999年由Daniel Robbins 和一些开发人员开发的。目标就是创建一个没有预编译的二进制文件的Linux发行版并根据所在的硬件平台进行调整。中间因为Gentoo 缺少关键项目，没有自己的包管理系统，后面Robbins 受到FreeBSD包管理系统的启发，开发出了自己的包管理系统，被称为是portage。 Gentoo没有二进制组件，它的包树中只包含源代码，这使它成为可以移植到其他架构上的理想的操作系统。当然，它的不足之处就是需要漫长的安装时间和大量的人工参与。不过，这不就是我们学习Linux的目的嘛。  Gentoo与其他发行版的异同  Gentoo安装和大多数流行的Linux发行版很多不同的地方。虽然有自启动光盘，但是没有安装程序。安装Gentoo时，所有事情都是通过命令行手动操作的。没有配置向导也没有GUI工具。不过，它有一个非常有用的安装指南（安装使用手册）。 与其他发行版相比，Gentoo的另外一个不同点在于它没有发行版本。Gentoo是一个元发行版。元发行版指的是它会一直更新下去。使用元发行版的好处在于你可以随时更新到最新的版本程序。缺点就是你将得到非常复杂的包版本，这个版本没有经过彻底的测试，这点与Arch（另一个Linux的发行版本）是一样的。 Gentoo的处理包的方式是一大不同点。大多数发行版使用二进制包的形式来发布包。Gentoo中发布软件包的系统被称为portage。Gentoo的开发人员是受到FreeBSD的ports collection的启发，在port collection 中只有源代码和包含构建源代码的方法的小文件会发布给终端用户。这被称为源代码发布。Gentoo的portage系统是由一组文件组成的，这个文件被称为ebuild，必要的补丁文件是由Gentoo社区创建。Ebuild文件是由一个被称为emerge的工具来读取。 这个文件仅仅运行标准的./configure、make和make install 工具。这意味着你想要运行在Gentoo系统中的每一个应用程序都需要从源代码进行编译。Gentoo的一切都是从源代码进行编译的，因此，这个发行版要负责GCC工具链中的代码修复工作，包括那些改进GCC的性能优化。源代码的发布除了给Linux社区整体带来益处，也为终端用户带来了巨大的好处。当你在Gentoo中安装一个包是，你将可以通过选项来指定哪些模块被安装，哪些不需要安装，这个用来标记的方法就是use。use标记在构建的配置阶段使用，它们可以设置你想要编译应用程序的哪些部分，这样可以为你提供一个快速简洁的轻量级系统。不过，当你发现一些应用程序需要依赖你前面剔出的功能时，那么你就得需要花费更多的时间重新编译程序才能使用这些功能。- -  分区 我们是在树莓派上安装Gentoo，所以这里准备一个全新的SD卡，至少要有4GB。 拿到SD卡以后，首先我们为SD卡创建分区。==这里，要提醒一下，读卡器上有一个开关可以控制SD卡的读写性。如果，开关按了也没用，把卡拿出来，插拔多几次，主要是有的读卡器接触点不好，我就是遇到这个问题，卡了很长时间。==\n 引导分区，fat32格式 根分区，EXT4格式或者其他的Linux文件系统格式。  $ fdisk -l Disk /dev/sda：298.1 GiB，320072933376 字节，625142448 个扇区 单元：扇区 / 1 * 512 = 512 字节 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：dos 磁盘标识符：0x86258625 设备 启动 起点 末尾 扇区 大小 Id 类型 /dev/sda1 * 63 62926604 62926542 30G 7 HPFS/NTFS/exFAT /dev/sda2 62926605 625137344 562210740 268.1G f W95 扩展 (LBA) /dev/sda5 272658432 272863231 204800 100M 83 Linux /dev/sda6 272865280 281253887 8388608 4G 83 Linux /dev/sda7 281255936 616800255 335544320 160G 83 Linux /dev/sda8 616802304 620996607 4194304 2G 83 Linux /dev/sda9 62928896 188758015 125829120 60G 7 HPFS/NTFS/exFAT /dev/sda10 188760064 209731583 20971520 10G 83 Linux 分区表记录没有按磁盘顺序。 Disk /dev/sdb：14.9 GiB，15931539456 字节，31116288 个扇区 单元：扇区 / 1 * 512 = 512 字节 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：dos 磁盘标识符：0x00000000 设备 启动 起点 末尾 扇区 大小 Id 类型 /dev/sdb1 2048 31116287 31114240 14.9G c W95 FAT32 (LBA) $ fdisk /dev/sdb 欢迎使用 fdisk (util-linux 2.27)。 更改将停留在内存中，直到您决定将更改写入磁盘。 使用写入命令前请三思。 命令(输入 m 获取帮助)：p Disk /dev/sdb：14.9 GiB，15931539456 字节，31116288 个扇区 单元：扇区 / 1 * 512 = 512 字节 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：dos 磁盘标识符：0x00000000 设备 启动 起点 末尾 扇区 大小 Id 类型 /dev/sdb1 2048 31116287 31114240 14.9G c W95 FAT32 (LBA) 命令(输入 m 获取帮助)：d 已选择分区 1 分区 1 已删除。 命令(输入 m 获取帮助)： 命令(输入 m 获取帮助)：n 分区类型 p 主分区 (0个主分区，0个扩展分区，4空闲) e 扩展分区 (逻辑分区容器) 选择 (默认 p)：p 分区号 (1-4，默认 1)： 第一个扇区 (2048-31116287，默认 2048)： 上个扇区，+sectors 或 +size{K,M,G,T,P} (2048-31116287，默认 31116287)：+100M 创建了一个新分区 1，类型为“Linux”，大小为 100 MiB。 命令(输入 m 获取帮助)：n 分区类型 p 主分区 (1个主分区，0个扩展分区，3空闲) e 扩展分区 (逻辑分区容器) 选择 (默认 p)：p 分区号 (2-4，默认 2)： 第一个扇区 (206848-31116287，默认 206848)： 上个扇区，+sectors 或 +size{K,M,G,T,P} (206848-31116287，默认 31116287)： 创建了一个新分区 2，类型为“Linux”，大小为 14.8 GiB。 命令(输入 m 获取帮助)：p Disk /dev/sdb：14.9 GiB，15931539456 字节，31116288 个扇区 单元：扇区 / 1 * 512 = 512 字节 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：dos 磁盘标识符：0x00000000 设备 启动 起点 末尾 扇区 大小 Id 类型 /dev/sdb1 2048 206847 204800 100M 83 Linux /dev/sdb2 206848 31116287 30909440 14.8G 83 Linux 命令(输入 m 获取帮助)：t 分区号 (1,2，默认 2)：1 分区类型(输入 L 列出所有类型)：c 已将分区“Linux”的类型更改为“W95 FAT32 (LBA)”。 命令(输入 m 获取帮助)：p Disk /dev/sdb：14.9 GiB，15931539456 字节，31116288 个扇区 单元：扇区 / 1 * 512 = 512 字节 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：dos 磁盘标识符：0x00000000 设备 启动 起点 末尾 扇区 大小 Id 类型 /dev/sdb1 2048 206847 204800 100M c W95 FAT32 (LBA) /dev/sdb2 206848 31116287 30909440 14.8G 83 Linux 命令(输入 m 获取帮助)：w 分区表已调整。 将调用 ioctl() 来重新读分区表。 正在同步磁盘。 接下来，将分区按照它们自己的文件系统格式进行格式化。\n$ mkfs /dev/sdb1 mke2fs 1.42.12 (29-Aug-2014) /dev/sdb1 contains a ext2 file system last mounted on /mnt/cdrom/armv7 on Thu Sep 24 19:40:44 2015 无论如何也要继续? (y,n) y Creating filesystem with 102400 1k blocks and 25688 inodes Filesystem UUID: 256e4119-5d49-4303-9ca2-a28638838ce6 Superblock backups stored on blocks: 8193, 24577, 40961, 57345, 73729 Allocating group tables: 完成 正在写入inode表: 完成 Writing superblocks and filesystem accounting information: 完成 $ mkfs.ext4 /dev/sdb2 mke2fs 1.42.12 (29-Aug-2014) Creating filesystem with 3863680 4k blocks and 966656 inodes Filesystem UUID: a0a95364-389a-4c4d-b63e-e1e61ed4b6c3 Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208 Allocating group tables: 完成 正在写入inode表: 完成 Creating journal (32768 blocks): 完成 Writing superblocks and filesystem accounting information: 完成 现在，我们已经创建好了两个可以使用的文件系统。然后，我们把相应分区挂载到/mnt 目录下。\n$ mkdir -p /mnt/raspberry/ $ mount /dev/sdb2 /mnt/raspberry #### 首先挂载根分区 $ mkdir -p /mnt/raspberry/boot \u0026\u0026 mount /dev/sdb1 /mnt/raspberry/boot ### 再挂载引导分区到根分区目录里的boot下。 这个引导分区和其他的树莓派引导分区类似。它包含基金会提供的固件、命令行参数、配置文件和内核。创建引导文件系统的第一步是从基金会的GitHub网站上获取固件文件： https://github.com/raspberrypi/firmware/tree/master/boot\n$ cd /mnt/raspberry/boot $ wget https://github.com/raspberrypi/firmware/tree/master/boot/bootcode.bin $ wget https://github.com/raspberrypi/firmware/tree/master/boot/start.elf $ wget https://github.com/raspberrypi/firmware/tree/master/boot/fixup.dat 分别下载这三个文件就可以了。接下来，需要创建cmdline.txt 和 config.txt 两个文件。 内容如下：\n$ cat cmdline.txt root=/dev/mmcblk0p2 rootdelay=2 $ cat config.txt gpu_mem=32 ######完成以上步骤，用ls -l 看一下引导分区现在的文件。 $ ls -l 总用量 104 -rw-r--r-- 1 root root 29026 9月 24 22:54 bootcode.bin -rw-r--r-- 1 root root 32 9月 24 22:59 cmdline.txt -rw-r--r-- 1 root root 11 9月 24 23:00 config.txt -rw-r--r-- 1 root root 29219 9月 24 22:56 fixup.dat drwx------ 2 root root 12288 9月 24 22:33 lost+found -rw-r--r-- 1 root root 29221 9月 24 22:56 start.elf 安装 下载系统包 http://distfiles.gentoo.org/releases/arm/autobuilds/current-stage3-armv7a_hardfp/\n$ cd ~/Downloads/ $ wget http://distfiles.gentoo.org/releases/arm/autobuilds/current-stage3-armv7a_hardfp/stage3-armv7a_hardfp-20150730.tar.bz2 $ tar xfj ~/Downloads/stage3-armv7a_hardfp-20150730.tar.bz2 -C /mnt/raspberry ### -C 指定解压的目录。解压需要一些时间，完成以后，看上去如下： $ ls -al 总用量 89 drwxr-xr-x 20 root root 4096 7月 30 13:50 . drwxr-xr-x 4 root root 4096 9月 24 22:38 .. drwxr-xr-x 2 root root 4096 7月 30 21:22 bin drwxr-xr-x 3 root root 1024 7月 30 13:50 boot drwxr-xr-x 3 root root 4096 7月 30 13:50 dev drwxr-xr-x 31 root root 4096 7月 30 21:31 etc drwxr-xr-x 2 root root 4096 7月 30 13:50 home drwxr-xr-x 10 root root 4096 7月 30 21:27 lib drwx------ 2 root root 16384 9月 24 22:33 lost+found drwxr-xr-x 2 root root 4096 7月 30 13:50 media drwxr-xr-x 2 root root 4096 7月 30 13:50 mnt drwxr-xr-x 2 root root 4096 7月 30 13:50 opt drwxr-xr-x 2 root root 4096 7月 30 13:18 proc drwx------ 2 root root 4096 7月 30 13:50 root drwxr-xr-x 3 root root 4096 7月 30 21:22 run drwxr-xr-x 2 root root 4096 7月 30 21:31 sbin drwxr-xr-x 2 root root 4096 7月 30 13:50 sys drwxrwxrwt 2 root root 4096 7月 30 21:31 tmp drwxr-xr-x 11 root root 4096 7月 30 21:31 usr drwxr-xr-x 9 root root 4096 7月 30 13:50 var 到这里，相信大家都很熟悉这个目录了。\n配置系统文件 第一步就是配置fstab，因为这是系统引导完成以后最先需要挂载好文件系统。==这里千万要注意修改的是 /mnt/raspberry/etc/fstab ==\n$ cat etc/fstab # \u003cfs\u003e\t\u003cmountpoint\u003e\t\u003ctype\u003e\t\u003copts\u003e\t\u003cdump/pass\u003e # NOTE: If your BOOT partition is ReiserFS, add the notail option to opts. /dev/mmcblk0p1\t/boot ext2\tnoauto,noatime\t1 2 /dev/mmcblk0p2\t/\text4\tnoatime 0 1 不要使用/dev/sdX设置的引用 。因为SD卡在树莓派上被视为/dev/mmcdlk0 。因为无法chroot到新的构建环境中，所以需要手动设置一些东西。首先，为Gentoo系统设置一个新的root用户密码。如下，\n$ openssl passwd -1 Password: Verifying - Password: $1$ZoQIFaY4$3Re0RSS0qu6nds3wvqlRf1 以上，最后一行就是我们的encrypted密码，把它放到/etc/shadow文件中。\n$ cat etc/shadow | grep root root:$1$ZoQIFaY4$3Re0RSS0qu6nds3wvqlRf1:10770:0::::: 配置 portage 到目前为止，已经完成了所有的系统配置。但是，这还不是最终的系统，现在我们必须解压当前的portage集合。这样，才能在系统引导时，构建应用程序。下载，我们到以下地址去下载portage包。 http://distfiles.gentoo.org/releases/snapshots/current/portage-lastest.tar.bz2\n$ cd ~/Downloads/ $ wget http://distfiles.gentoo.org/releases/snapshots/current/portage-latest.tar.bz2 $ tar xjvpf ~/Downloads/portage-latest.tar.bz2 -C /mnt/raspberry/usr 交叉编译环境 构造一个最小的 Linux 系统， ==主要分为两步：第一步是构建一个宿主系统无关的新工具链（编译器、汇编器、链接器、库和一些有用的工具）。第二步则是使用该工具链构建其它的基础工具。== 这里说的工具链就是说的交叉编译环境。\n下载系统内核 到了这一步以后，我们需要为新的Gentoo系统构建一个内核。为了完成这一步，需要有相关配置交叉编译环境基础知识。还需要内核源码,这里我们使用树莓派官方内核源码，因为这将包含所有已经打好的树莓派的补丁。到GitHub上clone一份内核源码或者下载zip包，如下：\n$ git clone https://github.com/raspberrypi/linux $ cd linux 为什么要使用交叉编译环境 交叉编译是在你的宿主系统上编译不同机器类型的应用程序。因为，树莓派使用的ARM架构与宿主机系统x86机器类型不同，只有使用相同的CPU机器类型才能使用chroot引导新系统。所以，这里就得用到交叉编译环境，在宿主系统上编译出ARM架构的树莓派。 在开始之前，希望大家可以先看一下《Linux 从零开始》 。\ncrosstool-NG 暂时写到这里，以后再补充。\n","description":"","tags":["linux","Gentoo","Raspberry Pi"],"title":"树莓派安装Gentoo Linux","uri":"/posts/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%AE%89%E8%A3%85gentoo-linux/"},{"categories":null,"content":"今天配置安装ssl证书碰到了不少的问题，这里记录一下。\n HTTP协议默认情况下是不加密的，各种密码，邮件的传输都是明文的，极有可能被互联网上的黑客给获取，造成隐私泄漏。 SSL是Secure Socket Layer的简称，具体的作用就是在部署了SSL证书的网站跟用户浏览器之间建立一个安全的会话。\n nginx编译安装ssl模块 在说安装证书之前，我先说一下，nginx 要想使用ssl需要在编译安装的时候加上配置参数 --with-zlib=/data/nginx/lib/ 使用命令先看一下nginx配置\n$ /usr/local/nginx/sbin/nginx -V nginx version: nginx/1.9.0 built by gcc 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) built with OpenSSL 1.0.1e-fips 11 Feb 2013 TLS SNI support enabled configure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module 如果在configure arguments: 没有找到ssl相关模块，就得重新编译一下。找到nginx源码包，执行以下命令，如下：\n==这里提醒一下，安装软件的时候我觉得还是在root权限下方便，而且可以避免不必要的无权限执行报错，即使有sudo的权限。==\n$ cd nginx-1.9.0 $ ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module ##这里的stub模块是个统计性能用的，与本文无关，你也可以不安装这个。 $ make ##这里不要使用 make install，否则就覆盖安装了 make完之后在objs目录下就多了个nginx，这个就是新版本的程序了 $ cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak $ cp objs/nginx /usr/local/nginx/sbin/nginx $ /usr/local/nginx/sbin/nginx -V ##这里就可以使用新版本的程序看一下编译参数里已经有ssl模块了。 证书安装 这里说一下，免费的SSL与付费的SSL还是有区别的，我主要是为博客后台登陆使用SSL，学习配置一下。\nStartCom公司是到目前止仅有的还提供免费SSL服务的公司（应该是吧，我也是听别人说的），支持多种浏览器的正常识别，只要通过他们的个人信息审核就可以免费使用一年的时间。我自己审核的时候，本想随便写个英文名称，地址，但是都被弊掉了。建议填写个人信息的时候还是要尽量真实。这样才能够一次性通过邮件审核。 StartSSL官方首页 具体申请流程我就不说了，打开官方网站看一下就知道了。\n我们来说一下，安装的流程： 首先使用ssh登陆vps，执行如下命令生成证书\n$ openssl req -new -newkey rsa:2048 -nodes -out server.csr -keyout server.key 以上生成的server.csr 需要把内容粘贴到 StartSSL 去生成域名证书了。\n这里生成的server.key 是没有passphrase的，所以这一节我们可以跳过不看。如果有配置密码的话，我们需要去掉private key的passphrase才能让Nginx自由自在的启动。\n$ cp server.key server.key.bak $ sudo openssl rsa -in server.key.bak -out server.key 开始配置nginx server { listen 443 ssl; server_name hcaijin.com www.hcaijin.com; location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:2368; } ssl_certificate /usr/local/nginx/ssl/hcjwebssl.crt; ssl_certificate_key /usr/local/nginx/ssl/hcjnopassssl.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; } 配置把http的请求转到https\nserver { listen 80; server_name hcaijin.com www.hcaijin.com; location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:2368; } #rewrite ^(.*) https://$server_name$1 permanent; location ~ /ghost(/.*) { rewrite ^ https://$server_name$request_uri? permanent; } } $ /etc/init.d/nginx restart ##重启一下nginx服务 解决Firefox浏览器不信任StartSSL免费SSL的问题 $ wget http://cert.startssl.com/certs/ca.pem $ wget http://cert.startssl.com/certs/sub.class1.server.ca.pem $ sudo cat ca.pem sub.class1.server.ca.pem \u003e\u003e server.crt $ /etc/init.d/nginx restart ","description":"","tags":["ghost","nginx","https","openssl"],"title":"Nginx配置博客ghost使用https 及安装StartSSL免费SSL证书","uri":"/posts/nginx%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2ghost%E4%BD%BF%E7%94%A8https-%E5%8F%8A%E5%AE%89%E8%A3%85startssl%E5%85%8D%E8%B4%B9ssl%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":" 蓝牙是一个短距离无线通信标准，适用于手机、计算机和其他电子设备之间的通信。在 Linux 中，通常使用的蓝牙协议栈实现是 BlueZ.\n 安装 为了使用蓝牙(Blutooth)，必须要安装官方仓库中的 bluez 软件包。\n$ sudo pacman -S bluez bluez-utils  bluez会使用dbus 服务读取设置和进行pin(个人识别码 personal identification number)配对。蓝牙(Bluetooth)协议需要bluetooth服务来支撑：\n$ sudo systemctl enable bluetooth.service $ sudo systemctl start bluetooth.service  加载通用蓝牙驱动程序，如果还没有装载：\n$ modprobe btusb  配置 bluetoothctl 使用bluetoothctl 需要安装bluez-utils 包。这个在上一步里已经执行过了，这里就直接说配置与使用的方法：\n$ bluetoothctl  help 列出帮助文档。  首先执行 power on 打开蓝牙适配器的电源开关，这样蓝牙的LED灯会亮起(默认是关闭的)。 先用命令 devices 列出有已匹配的设备MAC地址 如果列表为空，那么就要使用 scan on 来扫描网络中开启蓝牙的设备 开启代理 agent on 输入命令 pair [MAC Address]  匹配两个蓝牙设备 如果使用设备没有PIN，要成功地重新连接设备之前，可能需要手动信任设备。输入 trust [MAC Address]  如果以上步骤都没有问题的话，那么就可以链接你的蓝牙设备了。 connect [MAC Address]  Obex 使用obexctl是在蓝牙设备之间发送和接收文件的工具，是随bluez包安装好了的,在终端直接输入 obexctl 就可以进入obex环境，如图： 另外还有一个命令行工具obexfs (包括obexfs,obexftp等)\n$ sudo pacman -S obexfs  安装好了就可以使用命令直接挂载蓝牙设备到本地目录，\n$ obexfs -b MAC_address_of_device -p /mnt/bluez/  一旦你完成了，卸载的设备使用以下命令：\n$ fusermount -u /mnt/bluez/  如果您的设备支持FTP服务，但你不希望加载该设备，您可以使用obexftp传输文件在设备之间。 发送文件：\n$ obexftp -b MAC_address_of_device -p /path/to/file  接收文件：\n$ obexftp -b MAC_address_of_device -g filename  Bluetooth USB 适配器 如果你在使用USB适配器，你应当确认你的适配器被正确识别。你可以在插入适配器时通过查看/var/log/messages.log （或者journalctl -f)，\n$ tail -f /var/log/messages.log  这应当会出现类似于下面所示的信息：\nMay 2 23:36:40 tatooine usb 4-1: new full speed USB device using uhci_hcd and address 9 May 2 23:36:40 tatooine usb 4-1: configuration #1 chosen from 1 choice May 2 23:36:41 tatooine hcid[8109]: HCI dev 0 registered May 2 23:36:41 tatooine hcid[8109]: HCI dev 0 up May 2 23:36:41 tatooine hcid[8109]: Device hci0 has been added May 2 23:36:41 tatooine hcid[8109]: Starting security manager 0 May 2 23:36:41 tatooine hcid[8109]: Device hci0 has been activated\n如果你只得到了前面两行，说明了电脑发现了这个设备，但是你需要手动启动它。 例如：\n $ hciconfig -a hci0 $ hciconfig hci0 up  如果不能从你的手机发现电脑，那么就需要启用PSCAN和ISCAN：\n $ hciconfig hci0 piscan  注意: 检查/etc/bluetooth/main.conf中的发现倒计时和配对倒计时 试着在 /etc/bluetooth/main.conf 改变设备的class 修改：Class = 0x100100\n==参考：https://wiki.archlinux.org/index.php/Bluetooth ==\n","description":"","tags":["archlinux","bluetooth"],"title":"Arch Linux 配置Bluetooth","uri":"/posts/arch-linux-%E9%85%8D%E7%BD%AEbluetooth/"},{"categories":null,"content":"今天做csv导出遇到订单号太长导致导出来用EXCEL打开显示为科学计数了，最后几位直接显示为0。但是用文本方式打开订单号是正常的，这说明一定是与EXcel有关系。 GOOGLE了一下，找到EXCEL相关介绍：\n Excel显示数字时，如果数字大于12位，它会自动转化为科学计数法；如果数字大于15位，它不仅用于科学技术费表示，还会只保留高15位，其他位都变0。\n $oid = \"\\t\".$val['oid'];  如果是phpexcel导出的话，把”\\t\"换成” “即可。\n","description":"","tags":["csv","excel","phpexcel"],"title":"导出CSV文件，对长数字字符会自动显示科学计数解决方法","uri":"/posts/%E5%AF%BC%E5%87%BAcsv%E6%96%87%E4%BB%B6%E5%AF%B9%E9%95%BF%E6%95%B0%E5%AD%97%E5%AD%97%E7%AC%A6%E4%BC%9A%E8%87%AA%E5%8A%A8%E6%98%BE%E7%A4%BA%E7%A7%91%E5%AD%A6%E8%AE%A1%E6%95%B0%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"categories":null,"content":"无线网卡异常，有很多种原因造成。这里我是因为有做AP共享WIFI，本来好好的，不知道怎么实然，我手机wifi断了，再看，从PC共享的WIFI竟然挂了。 就这样，下班回家，准备链接无线路由，因为有换新的网，得重新链接：\n $ sudo wifi-menu -o  竟然报No networks found\n重启了问题依然存在，没办法，只能用有线先连着。 开始Google：No networks found 我一开始就找错了方向，自然是没有找到解决的方法。\n经过这次，让我对日志的记录有了更深的认识，以前，觉得日志记录太难看得懂了，从来都是很少去看，浪费了很多时间在无用的地方，这里给自己个警戒，凡是就得先看日志信息。\n这样，接下来，在日志里有发现有这个错误 Operation not possible due to RF-kill Google一下，就找到了问题的关键，原因RF-KILL其实是一个打开和关闭无线设备的工具。 由此可以知道，这是一打开无线设备wifi的错误。 因为我用的arch没有安装rfkill,执行：\n $ sudo pacman -S rfkill  安装好以后，为了查看当前的无限网卡的状态，执行命令rfkill list all ——列出所有无线设备的当前状态。结果如下： 发现 Hard blocked 和 soft blocked 之间的同步失败,具体原因可以看这里“SIOCSIFFLAGS: Operation not possible due to RF-kill”?\n找到问题原因，我们可以使用命令使软硬设备同步:\n$ rfkill unblock wifi  用命令 rfkill list all 列出所有无线设备状态看一下结果， 好了，无线网卡状态异常的问题修复了。\n","description":"","tags":["linux","wifi","RF-kill"],"title":"linux 无线网卡状态异常修复","uri":"/posts/linux-%E6%97%A0%E7%BA%BF%E7%BD%91%E5%8D%A1%E7%8A%B6%E6%80%81%E5%BC%82%E5%B8%B8%E4%BF%AE%E5%A4%8D/"},{"categories":null,"content":"安装前环境检查 因为pptp需要MPPE的支持，所以首先检测系统是否符已经编译了MPPE。 下面介绍两种检测方法，只要符合其中的一条就可以\n第一种：  # zgrep MPPE /proc/config.gz CONFIG_PPP_MPPE=y # cat /dev/net/tun cat: /dev/net/tun: File descriptor in bad state  第二种： 网上大多数资料还提到了另一个测试命令\n$ modprobe ppp-compress-18 \u0026\u0026 echo ok FATAL: Module ppp_mppe not found.  如果返回“OK”说明可以安装PPTP，我查了一下，这个命令是在CentOS 4.4版本中有人提出的，但是经过实际测试，发现在我的环境中非但没有效果，而且报错。 所以如果modprobe ppp-compress-18 \u0026\u0026 echo ok没有显示“OK”甚至报错，并不代表不能安装。最好还是用上面那种方法查看。\n安装依赖 由于pptp需要iptables支持，所以需要安装iptables。如果您的服务器上已经安装了iptables，那么可以只安装pptp\n$ yum install -y ppp iptables  注意：这里先安装的是ppp而不是pptp，不要打错了。另：PPP是一种数据链路层协议类似我们熟知的pppoe 接下来就是一大堆的信息，无非是寻找最快的源，找到后下载相关安装包，下载完成自动安装。 如果回到提示符状态，并且安装结果为Complete!，说明安装成功。\n安装pptp 现在我们可以正式安装VPN Server了。这里我们选择pptp(VPN 协议的一种),因为简单，一条命令搞定。剩下的无非是一些配置。 yum -y install pptpd\n配置pptp 编辑/etc/ppp/options.pptpd pptpd安装完成后，编辑/etc/pptpd.conf文件，去掉下面两行的注释或者直接添加这两行(在文件的最后).这一步是配置ip地址的范围。\nlocalip 192.168.0.1 remoteip 192.168.0.100-150\n设置使用pptp的用户名和密码 然后在/etc/ppp/chap-secrets文件中添加VPN用户，按照下面的格式,每个用户一行。\nusername pptpd password *\n配置DNS服务器 为了让你的用户连上VPN后能够正常地解析域名，我们需要手动设置DNS. 编辑/etc/ppp/options，找到ms-dns这一项，设置你的DNS.这里我推荐的是Google 最近发布的Public DNS,原因是因为好记。\nms-dns 8.8.8.8 ms-dns 209.244.0.3 ms-dns 208.67.222.222 ms-dns 8.8.4.4\n修改内核设置，使其支持转发。 编辑/etc/sysctl.conf文件，找到”net.ipv4.ip_forward=1″这一行，去掉前面的注释并注释掉 “net.ipv4.tcp_syncookies=1”。\nnet.ipv4.ip_forward=1 #net.ipv4.tcp_syncookies = 1  运行下面的命令让配置生效。\n$ sysctl -p  iptables转发 $ iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j SNAT --to-source 12.34.56.78  (适合于OpenVZ架构的VPS,12.34.56.78为您VPS的公网IP地址)\n$ iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j MASQUERADE  (适合于XEN架构的VPS) 以上两条命令分别对应OpenVZ架构和XEN架构的VPS，您的VPS是什么架构需要询问供应商。Linode采用的是XEN架构，所以输入\n我的是搬瓦工的vps,配置如下：\n$ iptables -t nat -A POSTROUTING -o venet0 -s 192.168.0.0/24 -j SNAT --to-source `ifconfig | grep 'inet addr:'| grep -v '127.0.0.1' | cut -d: -f2 | awk 'NR==1 { print $1}'`  运行 /etc/init.d/pptpd start ","description":"","tags":["pptp","iptables","vps"],"title":"PPTP 服务器端安装与配置详解","uri":"/posts/pptp-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"},{"categories":null,"content":"linux中除了常见的读（r）、写（w）、执行（x）权限以外，还有3个特殊的权限，分别是setuid、setgid和stick bit\nsetuid、setgid 先看个实例，查看你的/usr/bin/passwd 与/etc/passwd文件的权限\n# ls -l /usr/bin/passwd /etc/passwd -rw-r--r-- 1 root root 1549 08-19 13:54 /etc/passwd -rwsr-xr-x 1 root root 22984 2007-01-07 /usr/bin/passwd  众所周知，/etc/passwd文件存放的各个用户的账号与密码信息，/usr/bin/passwd是执行修改和查看此文件的程序，但从权限上看，/etc/passwd仅有root权限的写（w）权，可实际上每个用户都可以通过/usr/bin/passwd命令去修改这个文件，于是这里就涉及了linux里的特殊权限setuid，正如-rwsr-xr-x中的s\nsetuid就是：让普通用户拥有可以执行“只有root权限才能执行”的特殊权限，setgid同理指”组“\n作为普通用户是没有权限修改/etc/passwd文件的，但给/usr/bin/passwd以setuid权限后，普通用户就可以通过执行passwd命令，临时的拥有root权限，去修改/etc/passwd文件了\nstick bit （粘贴位） 再看个实例，查看你的/tmp目录的权限\n# ls -dl /tmp drwxrwxrwt 6 root root 4096 08-22 11:37 /tmp  tmp目录是所有用户共有的临时文件夹，所有用户都拥有读写权限，这就必然出现一个问题，A用户在/tmp里创建了文件a.file，此时B用户看了不爽，在/tmp里把它给删了（因为拥有读写权限），那肯定是不行的。实际上是不会发生这种情况，因为有特殊权限stick bit（粘贴位）权限，正如drwxrwxrwt中的最后一个t\nstick bit (粘贴位)就是：除非目录的属主和root用户有权限删除它，除此之外其它用户不能删除和修改这个目录。\n也就是说，在/tmp目录中，只有文件的拥有者和root才能对其进行修改和删除，其他用户则不行，避免了上面所说的问题产生。用途一般是把一个文件夹的的权限都打开，然后来共享文件，象/tmp目录一样。\n设置方法 setuid：chmod u+s xxx\nsetgid: chmod g+s xxx\nstick bit : chmod o+t xxx\n或者使用八进制方式，在原先的数字前加一个数字，三个权限所代表的进制数与一般权限的方式类似，如下:\n suid guid stick bit 1 1 1  所以：suid的二进制串为：100，换算十进制为：4\nguid的二进制串为:010,换算：2\nstick bit 二进制串：001，换算：1\n于是也可以这样设:setuid:chmod 4755 xxx\nsetgid:chmod 2755 xxx\nstick bit:chmod 1755 xxx\n最后，在一些文件设置了特殊权限后，字母不是小写的s或者t，而是大写的S和T，那代表此文件的特殊权限没有生效，是因为你尚未给它对应用户的x权限\n","description":"","tags":["linux","setuid","setgid","stick bit"],"title":"Linux中的文件特殊权限","uri":"/posts/linux%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90/"},{"categories":null,"content":"今天真是被这个问题给郁闷到了，调试了代码半天时间，终于从http://www.111cn.net/phper/php-cy/56742.htm 里找到了线索。就是存储session的目录权限不可写，或者目录空间満了写不进去就会出现这个BUG.\n$ ls -al / drwxr-xr-x. 12 root root 53248 Jun 15 17:14 tmp  发现/tmp 目录权限不对。\n后面，打开Thinkphp debug ,trace 页面查找到 open('/tmp/sess_ifoeq9834f98h4h54’,O_REIOR) promostion demoin\n 总结一下， 就是遇到问题，日志才是最好的排错地方。这里记录一下，以免以后又犯错，直接去调试代码，花费了不小的功夫，还找不到原因。\n ","description":"","tags":["php","session","Thinkphp"],"title":"php session 丢失BUG修改","uri":"/posts/php-session-%E4%B8%A2%E5%A4%B1bug%E4%BF%AE%E6%94%B9/"},{"categories":null,"content":" 利用 ssh 的用户配置文件 config 管理 ssh 会话。ssh 的用户配置文件是放在当前用户根目录下的 .ssh 文件夹里（~/.ssh/config，不存在则新创建一个），其配置写法如下：\n Host test User root HostName 192.168.3.152 PassWord V8kbwqsV0UGTob8EEeL4 Host * #PubkeyAuthentication no IdentityFile ~/.ssh/id_rsa  这样我们就可以使用如下命令直接登陆到hostname 为192.168.3.152 的服务器了：\n # ssh test  使用密钥的好处就是省去每次 ssh 登陆服务器时都要输入登陆密码的操作，这里使用 ssh-keygen 生成 ssh 密钥与公钥：\n # ssh-keygen -t rsa  把公钥 id_rsa.pub 上传到远程 192.168.3.152 服务器的 ~/.ssh/ 目录下：\n # ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.3.152  这样会在服务器的 ~/.ssh/ 目录下生成文件 authorized_keys\n这里注意一点：以 ssh publickey 的形式访问，对当前用户根目录下的 .ssh 文件夹里的目录文件是要有一定的权限要求，之前遇到过 ssh publickey 配置好了，不过用 publickey 登陆验证时则无效。所以，最好设下.ssh 目录权限为 700，authorized_keys 权限为 600，并检查当前用户目录所属的用户组，如：\n # ls -al .ssh/ total 12 drwx------ 2 root root 4096 Jun 13 16:20 . drwxr-xr-x. 5 other others 4096 Jun 13 16:15 .. -rw------- 1 root root 401 Jun 13 16:20 authorized_keys  以上，注意目录 .ssh/ 父目录用户所属用户组，用户。这样也会造成使用publickey 登陆验证时无效，还是提示要输入密码。\n # chown -R root.root /root/  当然，用密钥的方式连接服务器是需要服务器上的 ssh 支持的，需要 ssh 的配置文件（默认是在 etc/ssh/sshd_config）里的 PubkeyAuthentication 设置成 yes。如果要改登陆的端口，直接把 Port 改成你想要的端口值就行。修改完后重启下 ssh ，配置就生效：\n # /etc/init.d/sshd restart  然后，就可以使用ssh 别名登陆服务器了。\n用 ssh 作 socks5 代理翻墙，以后不用这样写了(hcj.com 为在墙外的代理服务器)：\n # ssh -CfNg -D1080 hcj.com  使用 scp 传送可以简写成这样：\n # scp ~/.ssh/id_rsa.pub test:~/.ssh/authorized_keys  执行远程 ssh 命令：\n # ssh test 'ls -al ~'  打包一个文件（假设当前目录有个名为 test 的文件夹），接着上传到远程服务器，最后解压文件\n # tar -zcvf - ./test/ | ssh test 'cd /user/; tar xvfz -'  ","description":"","tags":["linux","ssh"],"title":"LINUX ssh 用户配置文件 config 管理","uri":"/posts/linux-ssh-%E7%94%A8%E6%88%B7%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-config-%E7%AE%A1%E7%90%86/"},{"categories":null,"content":"1、linux下mysql安装完后是默认：区分表名的大小写，不区分列名的大小写；\n2、如何设置为不区分表名的大小写： 修改mysql配置文件/etc/mysql/my.cnf 中,在[mysqld]后添加lower_case_table_names=1，默认为0表示区分大小写，然后重启MYSQL服务。；\n3、Mysql 在不同的操作系统中大小写敏感区别： 3.1、MySQL在Linux下数据库名、表名、列名、别名大小写规则是这样的：\n 数据库名与表名是严格区分大小写的； 表的别名是严格区分大小写的； 列名与列的别名在所有的情况下均是忽略大小写的； 变量名也是严格区分大小写的；  3.2、MySQL在Windows下都不区分大小写。\n4、如果想在查询时区分字段值的大小写，则：字段值需要设置BINARY属性，设置的方法有多种：\nA、创建时设置： CREATE TABLE T( A VARCHAR(10) BINARY );\nB、使用alter修改： ALTER TABLE tablename MODIFY COLUMN cloname VARCHAR(45) BINARY;\n","description":"","tags":["mysql"],"title":"Mysql 设置大小写敏感","uri":"/posts/mysql-%E8%AE%BE%E7%BD%AE%E5%A4%A7%E5%B0%8F%E5%86%99%E6%95%8F%E6%84%9F/"},{"categories":null,"content":"1、先确认一下cvs的文件格式，确保与表编码一至。设为utf8 2、创建表，设置为utf8 3、登陆mysql, 导入csv文件\n$ mysql -uroot -p MariaDB []\u003e create database test; use test; MariaDB [test]\u003e LOAD DATA INFILE '/mysql/test_data.csv' REPLACE INTO TABLE test_table CHARACTER SET utf8 FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\r\\n';  注意：test_data.csv 要在mysql 的用户权限中，即使放到/tmp 目录下也是有问题的，暂时不知道怎么解决。\n$ sudo mkdir /mysql ; $ sudo chown -R mysql.mysql /mysql $ sudo cp ~/test_data.csv /mysql/  ","description":"","tags":["mysql","csv","utf8"],"title":"MySQL导入导出csv文件命令行操作","uri":"/posts/mysql%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BAcsv%E6%96%87%E4%BB%B6%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/"},{"categories":null,"content":"一般来说nginx 配置文件中对优化比较有作用的为以下几项：  worker_processes 8;  nginx 进程数，建议按照cpu 数目来指定，一般为它的倍数 (如,2个四核的cpu计为8)。\nworker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;  为每个进程分配cpu，上例中将8 个进程分配到8 个cpu，当然可以写多个，或者将一 个进程分配到多个cpu。\nworker_rlimit_nofile 65535;  这个指令是指当一个nginx 进程打开的最多文件描述符数目，理论值应该是最多打开文 件数（ulimit -n）与nginx 进程数相除，但是nginx 分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。\n现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。\n这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。\n查看linux系统文件描述符的方法：\n[root@web001 ~]# sysctl -a | grep fs.file\nfs.file-max = 789972\nfs.file-nr = 510 0 789972\nuse epoll;  使用epoll 的I/O 模型\n(\n补充说明:\n与apache相类，nginx针对不同的操作系统，有不同的事件模型\n A）标准事件模型 Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll B）高效事件模型  Kqueue：使用于 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X. 使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 Epoll: 使用于Linux内核2.6版本及以后的系统。 /dev/poll：使用于 Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。\n Eventport：使用于 Solaris 10. 为了防止出现内核崩溃的问题， 有必要安装安全补丁。  )\nworker_connections 65535;  每个进程允许的最多连接数， 理论上每台nginx 服务器的最大连接数为worker_processes*worker_connections。\nkeepalive_timeout 60;  keepalive 超时时间。\nclient_header_buffer_size 4k;  客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。\n分页大小可以用命令getconf PAGESIZE 取得。\n[root@web001 ~]# getconf PAGESIZE\n4096\n但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。\nopen_file_cache max=65535 inactive=60s;  这个将为打开文件指定缓存，默认是没有启用的，max 指定缓存数量，建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。\nopen_file_cache_valid 80s;  这个是指多长时间检查一次缓存的有效信息。\nopen_file_cache_min_uses 1;  open_file_cache 指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，它将被移除。\n关于内核参数的优化： net.ipv4.tcp_max_tw_buckets = 6000\ntimewait 的数量，默认是180000。\nnet.ipv4.ip_local_port_range = 1024 65000\n允许系统打开的端口范围。\nnet.ipv4.tcp_tw_recycle = 1\n启用timewait 快速回收。\nnet.ipv4.tcp_tw_reuse = 1\n开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接。\nnet.ipv4.tcp_syncookies = 1\n开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies 来处理。\nnet.core.somaxconn = 262144\nweb 应用中listen 函数的backlog 默认会给我们内核参数的net.core.somaxconn 限制到128，而nginx 定义的NGX_LISTEN_BACKLOG 默认为511，所以有必要调整这个值。\nnet.core.netdev_max_backlog = 262144\n每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。\nnet.ipv4.tcp_max_orphans = 262144\n系统中最多有多少个TCP 套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS 攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。\nnet.ipv4.tcp_max_syn_backlog = 262144\n记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M 内存的系统而言，缺省值是1024，小内存的系统则是128。\nnet.ipv4.tcp_timestamps = 0\n时间戳可以避免序列号的卷绕。一个1Gbps 的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。\nnet.ipv4.tcp_synack_retries = 1\n为了打开对端的连接，内核需要发送一个SYN 并附带一个回应前面一个SYN 的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量。\nnet.ipv4.tcp_syn_retries = 1\n在内核放弃建立连接之前发送SYN 包的数量。\nnet.ipv4.tcp_fin_timeout = 1\n如 果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2 状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60 秒。2.2 内核的通常值是180 秒，3你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB 服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2 的危险性比FIN-WAIT-1 要小，因为它最多只能吃掉1.5K 内存，但是它们的生存期长些。\nnet.ipv4.tcp_keepalive_time = 30\n当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时。\n下面贴一个完整的内核优化设置: vi /etc/sysctl.conf CentOS5.5中可以将所有内容清空直接替换为如下内容:\nnet.ipv4.ip_forward = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.default.accept_source_route = 0 kernel.sysrq = 0 kernel.core_uses_pid = 1 net.ipv4.tcp_syncookies = 1 kernel.msgmnb = 65536 kernel.msgmax = 65536 kernel.shmmax = 68719476736 kernel.shmall = 4294967296 net.ipv4.tcp_max_tw_buckets = 6000 net.ipv4.tcp_sack = 1 net.ipv4.tcp_window_scaling = 1 net.ipv4.tcp_rmem = 4096 87380 4194304 net.ipv4.tcp_wmem = 4096 16384 4194304 net.core.wmem_default = 8388608 net.core.rmem_default = 8388608 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 net.core.netdev_max_backlog = 262144 net.core.somaxconn = 262144 net.ipv4.tcp_max_orphans = 3276800 net.ipv4.tcp_max_syn_backlog = 262144 net.ipv4.tcp_timestamps = 0 net.ipv4.tcp_synack_retries = 1 net.ipv4.tcp_syn_retries = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_mem = 94500000 915000000 927000000 net.ipv4.tcp_fin_timeout = 1 net.ipv4.tcp_keepalive_time = 30 net.ipv4.ip_local_port_range = 1024 65000\n使配置立即生效可使用如下命令： /sbin/sysctl -p\n下面是关于系统连接数的优化 linux 默认值 open files 和 max user processes 为 1024\nulimit -n 1024\nulimit –u 1024\n问题描述： 说明 server 只允许同时打开 1024 个文件，处理 1024 个用户进程\n使用ulimit -a 可以查看当前系统的所有限制值，使用ulimit -n 可以查看当前的最大打开文件数。\n新装的linux 默认只有1024 ，当作负载较大的服务器时，很容易遇到error: too many open files 。因此，需要将其改大。\n解决方法：\n使用 ulimit –n 65535 可即时修改，但重启后就无效了。（注ulimit -SHn 65535 等效 ulimit -n 65535 ，-S 指soft ，-H 指hard)\n有如下三种修改方式：\n 在/etc/rc.local 中增加一行 ulimit -SHn 65535 在/etc/profile 中增加一行 ulimit -SHn 65535 在/etc/security/limits.conf 最后增加：   soft nofile 65535 hard nofile 65535 soft nproc 65535 hard nproc 65535  具体使用哪种，在 CentOS 中使用第1 种方式无效果，使用第3 种方式有效果，而在Debian 中使用第2 种有效果\nulimit -n 65535\nulimit -u 65535\n备注：ulimit 命令本身就有分软硬设置，加-H 就是硬，加-S 就是软默认显示的是软限制\nsoft 限制指的是当前系统生效的设置值。 hard 限制值可以被普通用户降低。但是不能增加。 soft 限制不能设置的比 hard 限制更高。 只有 root 用户才能够增加 hard 限制值。\n下面是一个简单的nginx 配置文件： user www www; worker_processes 8; worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000; error_log /www/log/nginx_error.log crit; pid /usr/local/nginx/nginx.pid; worker_rlimit_nofile 204800; events { use epoll; worker_connections 204800; } http { include mime.types; default_type application/octet-stream; charset utf-8; server_names_hash_bucket_size 128; client_header_buffer_size 2k; large_client_header_buffers 4 4k; client_max_body_size 8m; sendfile on; tcp_nopush on; keepalive_timeout 60; fastcgi_cache_path /usr/local/nginx/fastcgi_cache levels=1:2 keys_zone=TEST:10m inactive=5m; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 4k; fastcgi_buffers 8 4k; fastcgi_busy_buffers_size 8k; fastcgi_temp_file_write_size 8k; fastcgi_cache TEST; fastcgi_cache_valid 200 302 1h; fastcgi_cache_valid 301 1d; fastcgi_cache_valid any 1m; fastcgi_cache_min_uses 1; fastcgi_cache_use_stale error timeout invalid_header http_500; open_file_cache max=204800 inactive=20s; open_file_cache_min_uses 1; open_file_cache_valid 30s; tcp_nodelay on; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; server { listen 8080; server_name backup.aiju.com; index index.php index.htm; root /www/html/; location /status { stub_status on; } location ~ ..(php|php5)?$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fcgi.conf; } location ~ ..(gif|jpg|jpeg|png|bmp|swf|js|css)$ { expires 30d; } log_format access ‘$remote_addr – $remote_user [$time_local] “$request” ' ‘$status $body_bytes_sent “$http_referer” ' ‘“$http_user_agent” $http_x_forwarded_for’; access_log /www/log/access.log access; } }\n关于FastCGI 的几个指令： fastcgi_cache_path /usr/local/nginx/fastcgi_cache levels=1:2 keys_zone=TEST:10minactive=5m;\n这个指令为FastCGI 缓存指定一个路径，目录结构等级，关键字区域存储时间和非活动删除时间。\nfastcgi_connect_timeout 300;\n指定连接到后端FastCGI 的超时时间。\nfastcgi_send_timeout 300;\n向FastCGI 传送请求的超时时间，这个值是指已经完成两次握手后向FastCGI 传送请求的超时时间。\nfastcgi_read_timeout 300;\n接收FastCGI 应答的超时时间，这个值是指已经完成两次握手后接收FastCGI 应答的超时时间。\nfastcgi_buffer_size 4k;\n指定读取FastCGI 应答第一部分需要用多大的缓冲区，一般第一部分应答不会超过1k，由于页面大小为4k，所以这里设置为4k。\nfastcgi_buffers 8 4k;\n指定本地需要用多少和多大的缓冲区来缓冲FastCGI 的应答。\nfastcgi_busy_buffers_size 8k;\n这个指令我也不知道是做什么用，只知道默认值是fastcgi_buffers 的两倍。\nfastcgi_temp_file_write_size 8k;\n在写入fastcgi_temp_path 时将用多大的数据块，默认值是fastcgi_buffers 的两倍。\nfastcgi_cache TEST\n开启FastCGI 缓存并且为其制定一个名称。个人感觉开启缓存非常有用，可以有效降低CPU 负载，并且防止502 错误。\nfastcgi_cache_valid 200 302 1h; fastcgi_cache_valid 301 1d; fastcgi_cache_valid any 1m;\n为指定的应答代码指定缓存时间，如上例中将200，302 应答缓存一小时，301 应答缓存1 天，其他为1 分钟。\nfastcgi_cache_min_uses 1;\n缓存在fastcgi_cache_path 指令inactive 参数值时间内的最少使用次数，如上例，如果在5 分钟内某文件1 次也没有被使用，那么这个文件将被移除。\nfastcgi_cache_use_stale error timeout invalid_header http_500;\n不知道这个参数的作用，猜想应该是让nginx 知道哪些类型的缓存是没用的。以上为nginx 中FastCGI 相关参数，另外，FastCGI 自身也有一些配置需要进行优化，如果你使用php-fpm 来管理FastCGI，可以修改配置文件中的以下值：\n60\n同时处理的并发请求数，即它将开启最多60 个子线程来处理并发连接。\n102400\n最多打开文件数。\n204800\n每个进程在重置之前能够执行的最多请求数。\n","description":"","tags":["linux","nginx"],"title":"Nginx 配置高并发","uri":"/posts/nginx-%E9%85%8D%E7%BD%AE%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"categories":null,"content":"国外的Linux系统管理员守则中有这么一条：“慎用 rm -rf 命令，除非你知道此命令所带来的后果“\nLinux下删除文件并不是真实的删除磁盘分区中的文件，而是将文件的inode节点中的扇区指针清除，同时释放这些数据对应的数据块，当释放的数据块被系统重新分配时，那些被删除的数据就会被覆盖，所以误删除数据后，应马上卸载文件所在的分区。 每个文件有inode和block组成，inode是文件系统组成的最基本单元，它保存着文件的基本属性(大小、权限、属主组等)和存放的位置信息。而block用来存储数据。类似key-value，inode就是key，block对应value，通过key查找key对应的value。类似python的字典。\n查看根目录的inode值 ls -id / 2 / 一般”根”目录的inode值为2,一个分区挂载到一个目录下时，这个”根”目录的inode值为2\nmount /dev/sdb2 /mnt ls -id /mnt 2 /mnt 安装extundelete 下载extundelete wget http://ncu.dl.sourceforge.net/project/extundelete/extundelete/0.2.0/extundelete-0.2.0.tar.bz2 所需依赖包 yum -y install e2fsprogs e2fsprogs-libs e2fsprogs-devel 编译安装extundelte # tar jxvf extundelete-0.2.0.tar.bz2 # cd extundelte-0.2.0 # ./configure # make; make install 用extundelete恢复文件 模拟数据误删除环境 # mkdir /data # mkfs.ext4 /dev/sdb2 # mount /dev/sdb2 /data # cp /etc/hosts /data/ # mkdir /data/test # echo \"extundelete test\" \u003e /data/test/geek.txt # md5sum hosts #获取文件校验码 54fb6627dbaa37721048e4549db3224d hosts # md5sum test/geek.txt eb42e4b3f953ce00e78e11bf50652a80 test/geek.txt # rm -fr /data/* 卸载磁盘分区  umount /dev/sdb2 查询恢复数据信息 extundelete /dev/sdb2 --inode 2 …..\n File name | Inode number | Deleted status Directory block 8657: . 2 .. 2 lost+found 11 Deleted hosts 12 Deleted test 130817 Deleted 上面标记为Deleted是已经删除的文件或目录\n具体操作 开始恢复单个文件 默认恢复到当前目录下的RECOVERED_FILES目录中去\n extundelete /dev/sdb2 --restore-file hosts 恢复一个目录  extundelete /dev/sdb2 --restore-directory test/ 全部恢复  extundelete /dev/sdb2 --restore-all 检测是否恢复成功 # md5sum RECOVERED_FILES/hosts 获取文件校验码 54fb6627dbaa37721048e4549db3224d RECOVERED_FILES/hosts # md5sum RECOVERED_FILES/test/geek.txt eb42e4b3f953ce00e78e11bf50652a80 RECOVERED_FILES/test/geek.txt 校验码与之前的完全一致。\n","description":"","tags":["linux","extundelete","fdisk"],"title":"linux用extundelete恢复ext2、ext3、ext4下rm -rf误删除的数据","uri":"/posts/linux%E7%94%A8extundelete%E6%81%A2%E5%A4%8Dext2ext3ext4%E4%B8%8Brm-rf%E8%AF%AF%E5%88%A0%E9%99%A4%E7%9A%84%E6%95%B0%E6%8D%AE/"},{"categories":null,"content":"Ghost 搭建完能正常访问，可是墙内访问实在太慢了，按F12打开Chrome 开发者工具可以看到主要是 http://fonts.googleapis.com 这个访问使用了太长的时间。应该是GFW搞的鬼，使得 Google Fonts 服务也受影响了，Ghost 后台和默认主题都引用了 Google Fonts 服务，已至于每次打开自己的 Ghost 博客都很慢。\n这样我们就知道了问题的关键，马上登陆服务器，进入ghost目录。\n $ cd /data/www/ghost $ grep 'fonts.googleapis.com' -n --color -r .  使用sed删除相应的行\n $ sudo sed -i '19d' ./content/themes/casper/default.hbs  上面修改的地方其实就是删除 Ghost 系统内引用的 Google Fonts 英文字体文件，这对于国内的用户丝毫没有影响，毕竟我们用的是 中文 嘛。\n经过修改，Google Fonts 文件就被彻底清除了。然后重启 Ghost 系统，再登录你的博客看看吧！\n $ sudo -i $ pm2 restart ghost  ","description":"","tags":["ghost","google fonts","sed","grep"],"title":"Ghost 加载慢问题分析","uri":"/posts/ghost-%E5%8A%A0%E8%BD%BD%E6%85%A2%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"},{"categories":null,"content":"通常如果我们想获取一个文件里不重复的行的时候，我们可以直接通过 sort -u 命令，先把文件排序，然后去掉连续的重复行就行。\n可是，如果我们去掉重复行之后，还想保留文件原有的顺序，该怎么办呢？虽然 Linux 下有个看上去似乎很有用的命令叫 uniq，但事实上 uniq 命令仅仅只对连续的重复行有效。譬如我们有这样一个文件：\n$ cat file3 AAAA FFFF BBBB BBBB CCCC AAAA FFFF DDDD 如果不排序，直接使用 uniq 命令是没有用的：\n$ uniq file3 AAAA FFFF BBBB CCCC AAAA FFFF DDDD 使用 sort -u 的话，我们就丢失了文件原有的行的顺序了：\n$ sort -u file3 AAAA BBBB CCCC DDDD FFFF sort 和 uniq 一起用，和 sort -u 效果是一样的：\n$ sort file3 | uniq AAAA BBBB CCCC DDDD FFFF 一个终极的解决方案是使用 awk：\n$ awk ' !x[$0]++' file3 AAAA FFFF BBBB CCCC DDDD 简要解释一下，awk 的基本执行流程是，对文件的每一行，做一个指定的逻辑判断，如果逻辑判断成立，则执行指定的命令；如果逻辑判断不成立，则直接跳过这一行。\n我们这里写的 awk 命令是 !x[$0]++，意思是，首先创建一个 map 叫 x，然后用当前行的全文 $0 作为 map 的 key，到 map 中查找相应的 value，如果没找到，则整个表达式的值为真，可以执行之后的语句；如果找到了，则表达式的值为假，跳过这一行。由于表达式之后有 ++，因此如果某个 key 找不到对应的 value，该 ++ 操作会先把对应的 value 设成 0，然后再自增成 1，这样下次再遇到重复的行的时候，对应的 key 就能找到一个非 0 的 value 了。\n我们前面说过，awk 的流程是先判断表达式，表达式为真的时候就执行语句，可是我们前面写的这个 awk 命令里只有表达式，没有语句，那我们执行什么呢？原来，当语句被省略的时候，awk 就执行默认的语句，即打印整个完整的当前行。就这样，我们通过这个非常简短的 awk 命令实现了去除重复行并保留原有文件顺序的功能。\n引用\n本文部分翻译来自 Jadu Saikia 的博客，这个博客上有很多非常有用的小技巧，有空可以多看看。\n","description":"","tags":["linux","sed","bash","awk","sort","uniq"],"title":"保持文件原有排序去除重复行","uri":"/posts/%E4%BF%9D%E6%8C%81%E6%96%87%E4%BB%B6%E5%8E%9F%E6%9C%89%E6%8E%92%E5%BA%8F%E5%8E%BB%E9%99%A4%E9%87%8D%E5%A4%8D%E8%A1%8C/"},{"categories":null,"content":"安装 linux-lts 软件包 小贴士: 强烈推荐安装linux-lts作为备用内核，因为默认安装的linux内核比较新，容易与其它软件发生冲突\n linux-lts 是 Arch 官方提供的基于 Linux kernel 3.0 的长期支持内核。内核上游开发者针对此版本提供了长期支持，包括安全补丁和功能 backports。适用于需要长期支持的服务器环境用户，也可以将此内核作为新内核升级的后备内核。\n $ sudo pacman -S linux-lts\n配置启动 需要编辑 GRUB2 或 LILO 的启动加载项。\n以 GRUB2 为例：\n为了编辑/更新启动加载项，需要安装os-prober.\n安装后,再执行\n$ sudo grub-mkconfig -o /boot/grub/grub.cfg\n","description":"","tags":["linux","archlinux","grub"],"title":"安装配置Arch linux 相关","uri":"/posts/%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEarch-linux-%E7%9B%B8%E5%85%B3/"},{"categories":null,"content":" dd 是 Linux/UNIX 下的一个非常有用的命令，作用是用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。\n 常用： dd 命令生成文件test.data 大小为1024M\n$ dd if=/dev/zero of=test.data bs=1024M count=1\n整盘数据备份与恢复 将本地的/dev/sda1整盘备份到/dev/sda2\n$ dd if=/dev/sda1 of=/dev/sda2\n将/dev/sda2全盘数据备份到指定路径的image文件 $ dd if=/dev/sda2 of=/path/to/image 备份/dev/hdx全盘数据，并利用gzip工具进行压缩，保存到指定路径 $ dd if=/dev/hdx | gzip \u003e/path/to/image.gz 将备份文件恢复到指定盘： $ dd if=/path/to/image of=/dev/hdx\n将压缩的备份文件恢复到指定盘: $ gzip -dc /path/to/image.gz | dd of=/dev/hdx\n利用netcat远程备份 在源主机上执行此命令备份/dev/hda $ dd if=/dev/hda bs=16065b | netcat \u003c targethost-IP \u003e 1234\n在目的主机上执行此命令来接收数据并写入/dev/hdc\n$ netcat -l -p 1234 | dd of=/dev/hdc bs=16065b 以下两条指令是目的主机指令的变化分别采用bzip2 gzip对数据进行压缩，并将备份文件保存在当前目录。\n $ netcat -l -p 1234 | bzip2 \u003e partition.img $ netcat -l -p 1234 | gzip \u003e partition.img  备份MBR 备份磁盘开始的512Byte大小的MBR信息到指定文件 $ dd if=/dev/hdx of=/path/to/image count=1 bs=512\n将备份的MBR信息写到磁盘开始部分\n$ dd if=/path/to/image of=/dev/hdx\n磁盘管理 #### 得到最恰当的block size\n dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file dd if=/dev/zero bs=2048 count=500000 of=/root/1Gb.file dd if=/dev/zero bs=4096 count=250000 of=/root/1Gb.file dd if=/dev/zero bs=8192 count=125000 of=/root/1Gb.file  通过比较dd指令输出中所显示的命令执行时间，即可确定系统最佳的block size大小\n#### 测试硬盘读写速度\n$ dd if=/root/1Gb.file bs=64k | dd of=/dev/null $ dd if=/dev/zero of=/root/1Gb.file bs=1024 count=1000000  通过上两个命令输出的执行时间，可以计算出测试硬盘的读／写速度\n#### 修复硬盘 $ dd if=/dev/sda of=/dev/sda 当硬盘较长时间（比如1，2年）放置不使用后，磁盘上会产生magnetic flux point。当磁头读到这些区域时会遇到困难，并可能导致I/O错误。当这种情况影响到硬盘的第一个扇区时，可能导致硬盘报废。上边的命令有可能使这些数据起死回生。且这个过程是安全，高效的。\n其他 #### 将软驱数据备份到当前目录的disk.img文件\ndd if=/dev/fd0 of=disk.img count=1 bs=1440k\n#### 拷贝内存资料到硬盘 $ dd if=/dev/mem of=/root/mem.bin bs=1024\n将内存里的数据拷贝到root目录下的mem.bin文件\n#### 从光盘拷贝iso镜像\n$ dd if=/dev/cdrom of=/root/cd.iso 拷贝光盘数据到root文件夹下，并保存为cd.iso文件\n#### 增加Swap分区文件大小 $ dd if=/dev/zero of=/swapfile bs=1024 count=262144 创建一个足够大的文件（此处为256M）\n$ mkswap /swapfile\n把这个文件变成swap文件 $ swapon /swapfile 启用这个swap文件\n$ /swapfile swap swap defaults 0 0  在每次开机的时候自动加载swap文件, 需要在 /etc/fstab 文件中增加一行\n#### 销毁磁盘数据 $ dd if=/dev/urandom of=/dev/hda1 利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据。执行此操作以后，/dev/hda1将无法挂载，创建和拷贝操作无法执行。\n","description":"","tags":["linux","dd"],"title":"Linux dd","uri":"/posts/linux-dd/"},{"categories":null,"content":"预备知识  使用到的命令有tar,openssl,dd\n $ mkdir test_dir; cd test_dir/ ; touch test.file; cd .. ; ll test_dir/\n-rw-r–r– 1 hcaijin hcaijin 0 4月 30 16:35 test.file\n$ tar -zcvf - test_dir/ | openssl des3 -salt -k password | dd of=test_dir.tag\ntest_dir/ test_dir/test.file 记录了0+1 的读入 记录了0+1 的写出 176字节(176 B)已复制，0.0114724 秒，15.3 kB/秒\n$ dd if=test_dir.tag | openssl des3 -d -k password | tar -zxvf -\n记录了0+1 的读入 记录了0+1 的写出 176字节(176 B)已复制，0.000495166 秒，355 kB/秒 test_dir/ test_dir/test.file\n 详细openssl 可查看帮助页\n $ man openssl $ openssl enc -h  openssl 命令详解  SYNOPSIS openssl enc -ciphername [-in filename] [-out filename] [-pass arg] [-e] [-d] [-a] [-A] [-k password] [-kfile filename] [-K key] [-iv IV] [-p] [-P] [-bufsize number] [-nopad] [-debug] 说明： -chipername选项：加密算法，Openssl支持的算法在上面已经列出了，你只需选择其中一种算法即可实现文件加密功能。 -in选项：输入文件，对于加密来说，输入的应该是明文文件；对于解密来说，输入的应该是加密的文件。该选项后面直接跟文件名。 -out选项：输出文件，对于加密来说，输出的应该是加密后的文件名；对于解密来说，输出的应该是明文文件名。 -pass选项：选择输入口令的方式，输入源可以是标准输入设备，命令行输入，文件、变量等。 -e选项：实现加密功能（不使用-d选项的话默认是加密选项）。 -d选项：实现解密功能。 -a和-A选项：对文件进行BASE64编解码操作。 -K选项：手动输入加密密钥（不使用该选项，Openssl会使用口令自动提取加密密钥）。 -IV选项：输入初始变量（不使用该选项，Openssl会使用口令自动提取初始变量）。 -salt选项：是否使用盐值，默认是使用的。 -p选项：打印出加密算法使用的加密密钥。\n加密  举例：\n $ openssl enc -aes-128-cbc -in pacman.log -out pacman.log.aes  enter aes-128-cbc encryption password: ********************** Verifying - enter aes-128-cbc encryption password: ************************* 以上执行成功，生成加密文件 pacman.log.base64，使用以下命令解密： $ openssl enc -d -aes-128-cbc -in pacman.log.aes -out pacman.out.log  enter aes-128-cbc decryption password: ****************\n 下面方法的好处是你可以把它写入到脚本中，自动完成加密功能，不使用pass选项默认系统会提示输入密码并且确认，是需要人工操作的。\n $ openssl enc -aes-256-ecb -in pacman.log -out pacman.aes256.log -pass pass:123456 $ file pacman.aes256.log  pacman.aes256.log: data $ openssl enc -d -aes-256-ecb -out pacman256.log -in pacman.aes256.log \nenter aes-256-ecb decryption password: $ file pacman256.log  pacman256.log: UTF-8 Unicode text\n生成 pacman256.log 可以用file 看到文件解密为原来的类型了\n","description":"","tags":["openssl","linux"],"title":"Linux 加解密打包文件","uri":"/posts/linux-%E5%8A%A0%E8%A7%A3%E5%AF%86%E6%89%93%E5%8C%85%E6%96%87%E4%BB%B6/"},{"categories":null,"content":"下载安装  安装node.js 下载最新node.js 编译安装需要一段时间。\n  $ wget http://nodejs.org/dist/node-latest.tar.gz $ tar -xzf node-latest.tar.gz $ cd node-v $ ./configure $ make $ sudo make install  安装Ghost 安装扩展 $ yum install gcc-c++\nghost下载，安装 $ sudo mkdir -p /data/www/ $ cd /data/www/ $ wget https://ghost.org/zip/ghost-latest.zip $ unzip -d ghost ghost-latest.zip $ cd /var/www/ghost $ sudo npm install --production  安装完成后用 npm start 命令启动开发者模式下的 Ghost，用于检查有没有安装成功。 成功了，Ghost会运行在本地局域网内 127.0.0.1:2368。如果是在电脑上安装的，用浏览器访问此地址即可预览 Ghost。\n安装pm2  安装强大的进程守护程序“PM2”保证应用在开机以后自动启动\n 进入到/data/www/ghost，执行命令安装PM2：\n$ sudo npm install pm2 -g\n设置环境变量为“production”生产模式，“index.js”是程序启动的入口。最后给这个PM2的进程命名为\"ghost” 执行下面的命令：\n$ NODE_ENV=production pm2 start index.js --name \"ghost\" 设置开机自动运行网站：\n$ pm2 startup centos $ pm2 save\n可以执行 pm2 help 查看帮助。\n配置nginx  配置 Nginx 的反向代理：新建一个 Nginx 代理配置文件,并将代理指向到本地的Ghost端口:\n $ sudo vim /etc/nginx/conf.d/ghost.conf` server { listen 80; server_name My-Ghost-Blog.com; location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:2368; } }  重新启动 Nginx 服务器.\n$ sudo service nginx restart\n注意事项  修改服务器时间，这样新增的文章才能显示正常的本地时间 。\n $ sudo yun install -y ntp $ sudo cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime  ","description":"","tags":["nodejs","ghost","linux"],"title":"安装 node.js ghost 相关总结","uri":"/posts/%E5%AE%89%E8%A3%85-node-js-ghost-%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/"}]